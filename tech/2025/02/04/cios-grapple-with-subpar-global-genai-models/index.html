<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" itemscope itemtype="https://schema.org/WebApplication" lang="en"
  prefix="og: https://ogp.me/ns#">

<head>
  <meta charset="utf-8">
  <title>CIOs grapple with subpar global genAI models - Major Digest</title>
  <meta name="description" content="With the number of generative AI trials soaring in the enterprise, it is typical for the CIO to purchase numerous large language models from various model makers, tweaked for different geographies and languages.">
  <link rel="canonical" href="https://majordigest.com/tech/2025/02/04/cios-grapple-with-subpar-global-genai-models/">

  <meta itemprop="name" content="CIOs grapple with subpar global genAI models - Major Digest">
  <meta itemprop="description" content="With the number of generative AI trials soaring in the enterprise, it is typical for the CIO to purchase numerous large language models from various model makers, tweaked for different geographies and languages.">
  <link itemprop="url" href="https://majordigest.com/tech/2025/02/04/cios-grapple-with-subpar-global-genai-models/">
  <meta itemprop="image" content="https://majordigest.com/static12/tech/2025/02/04/cios-grapple-with-subpar-global-genai-models.webp">

  <meta property="og:title" content="CIOs grapple with subpar global genAI models - Major Digest">
  <meta property="og:description" content="With the number of generative AI trials soaring in the enterprise, it is typical for the CIO to purchase numerous large language models from various model makers, tweaked for different geographies and languages.">
  <meta property="og:url" content="https://majordigest.com/tech/2025/02/04/cios-grapple-with-subpar-global-genai-models/">
  <meta property="og:image" content="https://majordigest.com/static12/tech/2025/02/04/cios-grapple-with-subpar-global-genai-models.webp">
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="Major Digest">
  <meta property="og:locale" content="en_US">
  <meta property="fb:pages" content="113570554924596">
  <!-- <meta property="fb:app_id" content="490025408049997"> -->

  <meta name="twitter:title" content="CIOs grapple with subpar global genAI models - Major Digest">
  <meta name="twitter:description" content="With the number of generative AI trials soaring in the enterprise, it is typical for the CIO to purchase numerous large language models from various model makers, tweaked for different geographies and languages.">
  <meta name="twitter:url" content="https://majordigest.com/tech/2025/02/04/cios-grapple-with-subpar-global-genai-models/">
  <meta name="twitter:image" content="https://majordigest.com/static12/tech/2025/02/04/cios-grapple-with-subpar-global-genai-models.webp">
  <meta name="twitter:image:alt" content="CIOs grapple with subpar global genAI models - Major Digest">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@major_digest">
  <meta name="twitter:creator" content="@vpodk">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=5.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-touch-icon.png">
  <link rel="apple-touch-startup-image" href="/assets/icons/logo-512x512.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
  <link rel="mask-icon" href="/assets/icons/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-status-bar-style" content="black">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="apple-mobile-web-app-title" content="Major Digest">
  <meta name="application-name" content="Major Digest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel="manifest" href="/manifest.json?v=1.1.6">
  <link rel="stylesheet" href="/assets/styles.css?v=1.1.6">
  <link rel="alternate" type="application/rss+xml" title="Major Digest RSS Feed"
    href="https://majordigest.com/tech/feed.xml">
  <link rel="sitemap" type="application/xml" title="Major Digest Sitemap"
    href="https://majordigest.com/tech/sitemap.xml">
</head>

<body class="tech">
  <a href="#main" class="skip-nav">Skip to Main Content</a>
  <header>
    <span>
      <time datetime="2025-02-04T19:00:08.927Z" itemprop="datePublished">Tuesday, February 4, 2025</time> &nbsp;
    </span>
    <h1>
      <a href="/" aria-label="Major Digest Home"><img src="/assets/logo.svg" alt="Major Digest Home" width="225"
          height="50"></a>
      <span>CIOs grapple with subpar global genAI models - Major Digest</span>
    </h1>
  </header>
  <nav itemscope itemtype="https://schema.org/SiteNavigationElement">
    <a itemprop="url" href="/us/" title="The Latest U.S. News From Most Reliable Sources">U.S.</a>
    <a itemprop="url" href="/world/" title="Breaking News From Around the World">World</a>
    <a itemprop="url" href="/tech/" title="The Latest Tech News and Headlines">Technology</a>
    <a itemprop="url" href="/sports/" title="Stay Up to Date on Your Favorite Teams and Players">Sports</a>
    <a itemprop="url" href="/politics/" title="The Latest Political News and Headlines">Politics</a>
  </nav>
  <main id="main" aria-label="Main content">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
    "@type": "ListItem", "position": 1, "name": "Home",
    "item": "https://majordigest.com/"
  }, {
    "@type": "ListItem", "position": 2, "name": "tech",
    "item": "https://majordigest.com/tech/"
  }, {
    "@type": "ListItem", "position": 3, "name": "CIOs grapple with subpar global genAI models - Major Digest"
  }]
}
</script>
<div itemscope itemtype="https://schema.org/NewsArticle" class="article">
  <meta itemprop="dateModified" content="Tue, 04 Feb 2025 11:00:00 GMT">
  <meta itemprop="url" content="/tech/2025/02/04/cios-grapple-with-subpar-global-genai-models/">
  <h2 itemprop="headline">CIOs grapple with subpar global genAI models</h2>
  <div itemprop="articleBody">
    <figure>
      <img src="/static12/tech/2025/02/04/cios-grapple-with-subpar-global-genai-models.webp" alt="CIOs grapple with subpar global genAI models" itemprop="image" width="400" height="225"
        data-src="https://www.computerworld.com/wp-content/uploads/2025/02/3810687-0-78643600-1738688915-colorful-flags-flapping-in-wind-by-saj-shafique-via-unsplash.jpg?quality=50&strip=all">
      <figcaption>Credit: Computer World</figcaption>
    </figure>
    <div id="remove_no_follow">
		<div class="grid grid--cols-10@md grid--cols-8@lg article-column">
					  <div class="col-12 col-10@md col-6@lg col-start-3@lg">
						<div class="article-column__content">
<section class="wp-block-bigbite-multi-title"><div class="container"></div></section>



<p>With the number of generative AI trials soaring in the enterprise, it is typical for the CIO to purchase numerous large language models from various model makers, tweaked for different geographies and languages. But CIOs are discovering that non-English models are faring far more poorly than English ones, even when purchased from the same vendor.</p>



<p>There is nothing nefarious about that fact. It is simply because there is a lot less data available to train non-English models.</p>



<p>“It is almost guaranteed that all LLM implementations in languages other than English will perform with less accuracy and less relevance than implementations in English because of the vast disparity in training sample size,” said Akhil Seth, head of AI business development at consultant firm UST.</p>



<p>Less data delivers less comprehensiveness, less accuracy, and much more frequent hallucinations. (Hallucinations typically happen when the model has no information to answer the query, so it makes something up. Proud algorithms these LLMs can be.)</p>



<p>Nefarious or not, IT leaders at global companies need to deal with this situation or suffer subpar results for customers and employees who speak languages other than English.</p>



<p>The major model makers — OpenAI, Microsoft, Amazon/AWS, IBM, Google, Anthropic, and Perplexity, among others — do not typically divulge the volume of data each model is trained on, and certainly not the quality or nature of that data. Enterprises usually deal with this lack of transparency about training data via extensive testing, but that testing is often focused on the English language model, not those in other languages.</p>



<p>“There are concerns that this [imbalance of training data] would put applications leveraging non-English languages at an informational and computational disadvantage,” said Flavio Villanustre, global chief information security officer of LexisNexis Risk Solutions.</p>



<p>“The volume, richness, and variability in the underlying training data is key to obtaining high-quality runtime performance of the model.” Inquiries in languages that are underrepresented in the training data are likely to yield poor performance, he said.</p>



<h3 class="wp-block-heading" id="the-size-difference-can-be-extreme">The size difference can be extreme</h3>



<p>How much smaller are the datasets used in non-English models? That varies widely depending on the language. It’s not so much a matter of the number of people who speak that language as it is the volume of data in that language available for training. </p>



<p>Vasi Philomin, the VP and general manager for generative AI at Amazon Web Services (AWS), one of the leading AI as a Service vendors, estimated that the training datasets for non-English models are roughly “10 to 100 times smaller” than their English counterparts.</p>



<p>Although there is no precise way to predetermine how much data is available for training in a given language, Hans Florian, a distinguished research scientist for multilingual natural language processing at IBM, has a trick. “You can look at the number of Wikipedia pages in that language. That correlates quite well with the amount of data available in that language,” he said.</p>



<p>Training data availability also varies by industry, topic, and use case.</p>



<p>“If you want your language model to be multilingual, the best thing you can do is have parallel data in the languages you want to support,” said Mary Osborne, the senior product manager of AI and natural language processing at SAS. “That’s an easy proposition in places like Quebec, for example, where all their government data is created in both English and French. If you wanted to have an LLM that did a great job of answering questions about the Canadian government in both English and French, you’d have a good supply of data to pull that off,” Osbourne said.</p>



<p>“But if you wanted to add an obscure indigenous language like Cree or Micmac, those languages would be vastly underrepresented in the sample. They would yield poor results compared to English and French, because the model wouldn’t have seen enough data in those indigenous languages to do well,” she said.</p>



<p>Although dataset size is extremely important in a genAI model, data quality is also critical. Even though there are no objective benchmarks for assessing data quality, experts in various topics have a rough sense of what good and bad content looks like. In healthcare, for example, it might be the difference between using the <em>New England Journal of Medicine</em> or <em>Lancet</em> versus scraping the personal website of a chiropractor in Milwaukee.</p>



<p>Like dataset size, data quality often varies by geography, according to Jürgen Bross, senior research scientist and manager in multilingual at IBM. In Japan, for example, IBM needed to apply its own quality filtering, partly because so many quality web sites in Japan are behind strict paywalls. That meant that, on average, the available Japanese data was of lower quality. “Fewer newspapers and more product pages,” Bross said. </p>



<h3 class="wp-block-heading" id="quick-fixes-bring-limited-success">Quick fixes bring limited success</h3>



<p>UST’s Seth said the dataset challenges with non-English genAI models are not going to be easy to overcome. Some of the more obvious mechanisms to address the smaller training datasets for non-English models — including automated translation and more aggressive fine-tuning — come with their own negatives.</p>



<p>“Putting a [software] translator somewhere in the inference pipeline is an obvious quick fix, but it will no doubt introduce idiomatic inconsistencies in the generated output and potentially even in the interpretation of the input. Even multilingual models suffer from this,” Seth said.</p>



<p>Another popular countermeasure for non-English genAI models is using synthetic data to supplement the actual data. Synthetic data is typically generated by machine learning, which extrapolates patterns from real data to create likely data. The problem is that if the original data has even a hint of bias — which is common — synthetic data is likely to perpetuate and magnify that bias. Forgive the cliché, but it’s the genAI version of three steps forward, two steps back.</p>



<p>Indeed, LexisNexis’ Villanustre worries that this problem could get worse, hurting the accuracy and credibility of genAI-produced global analysis.</p>



<p>“There is an increasing portion of unstructured content on the internet that is currently created by generative AI models. If not careful, future models could be increasingly trained on output from other models, potentially amplifying biases and inaccuracies,” Villanustre said.</p>



<h3 class="wp-block-heading" id="practical-and-sometimes-expensive-approaches">Practical (and sometimes expensive) approaches</h3>



<p>So how can tech leaders better address the problem?</p>



<p>It starts during the procurement process. Although IT operations folks typically ask excellent questions about LLMs before they purchase, they tend to be overwhelmingly focused on the English version. It doesn’t occur to them that the quality delivered in the non-English models may be dramatically lower.</p>



<p>Jason Andersen, a VP and principal analyst with Moor Insights & Strategy, said CIOs need to do everything they can to get model makers to share more information about training data for <em>every</em> model being purchased or licensed. “There has to be much more transparency of data provenance,” he said. </p>



<p>Alternatively, CIOs can consider sourcing their non-English models from regional/local genAI firms that are native to that language. Although that approach might solve the problem for many geographies, it is going to meet strong resistance from many enterprise CIOs, said Rowan Curran, a senior analyst for genAI strategies at Forrester.</p>



<p>“Most enterprises are far more interested in sourcing their foundation models from their trusted providers,” which are generally the major hyperscalers, Curran said. “Enterprises really want to acquire those [model training] capabilities via their deployments on AWS, Google, or Microsoft. That gives [CIOs] a higher comfort level. They are hesitant to work with a startup.”</p>



<p>AWS’s Philomin said his team is trying to split the difference for IT customers by using a genAI marketplace approach, borrowing the technique from the AWS Marketplace — which in turn had borrowed the concept from its Amazon parent company. Amazon’s retail approach allows users to purchase from small merchants through Amazon, with Amazon taking a cut.</p>



<p>Amazon’s Bedrock Marketplace does something similar, providing access to a large number of genAI model makers globally. Although it certainly doesn’t mitigate all of the downsides of using a little-known provider in various geographies, Philomin argues that it addresses some of them.</p>



<p>“We are removing some of the risks, [such as] the resilience of the service and the support,” Philomin said. But he also stressed that those smaller players “are the seller of record, not AWS.” That caveat raises the question of how much help the AWS reseller role will be if something later blows up.</p>



<p>Another approach to address the training data disparity? Bypass the non-English models (for now) by employing bilingual humans who can comfortably interact with the English model.</p>



<p>“As a German native who works primarily in English, I’ve found that while LLMs are competent in German, they don’t quite reach native-level proficiency,” said Vincent Schmalbach, an independent AI engineer in Munich.</p>



<p>“For critical German-language content, I’ve developed a practical workflow. I interact with the LLM in English to get the highest quality output, then translate the final result to German. This approach consistently produces better results than working directly in German.”</p>



<p>The tactic that most genAI specialists agree on is that CIOs need to budget more money to test and fine-tune every non-English model they want to use. That money also needs to cover the additional processing and verification needed for non-English models. </p>



<p>That said, fine-tuning can only help so much. The training data is the heart of the genAI brain. If that is inadequate, more fine-tuning can be akin to trying to save a salad with rotting spinach by pouring on more salad dressing.</p>



<p>And allocating additional budget to fine-tuning models can be difficult because the number of variables — such as the specific languages, topics, and industry in question — is too numerous to offer any realistic guidance. But IBM’s Florian does offer a tiny bit of optimism: “You don’t need a permanent budget increase. It’s just a one-time budget increase, a one-time expense that you take.”</p>



<p>In other words, once the non-English model is fully integrated and supplemented, little to no funding is needed beyond whatever the English model needs.</p>



<h3 class="wp-block-heading" id="looking-ahead">Looking ahead</h3>



<p>There’s reason to hope that the disparity in the quality of output from models in various languages may be lessened or even negated in the coming years. That’s because a model based on a smaller dataset may not suffer from lower accuracy if the underlying data is of a higher quality.</p>



<p>One factor now coming into play lies in the difference between public and private data. An executive at one of the largest model makers — who asked to not be identified by name or employer — said the major LLM makers have pretty much captured as much of the data on the public internet as they can. They are continuing to harvest new data from the internet every day, of course, but those firms are shifting much of their data-gathering efforts to private sources such as corporations and universities. </p>



<p>“We have found a lot of super high-quality data, but we cannot get access to it because it’s not on the internet. We need to get agreements with the owners of this data to get access,” he said.</p>



<p>Tapping into private sources of information — including those in various countries around the world —will potentially improve the data quality for some topics and industries, and at the same time increase the amount of good training data available for non-English models. As the total universe of training data expands, the imbalance in the amount of training data across languages may matter less and less. However, this shift is also likely to raise prices as the model makers cut deals with third parties to license their private information.</p>



<p>Another factor that could minimize the dataset size problem in the next few years is an anticipated increase in unstructured data. Indeed, highly unstructured data — such as that collected by video drones watching businesses and their customers — could potentially sidestep language issues entirely, as the video analysis could be captured directly and saved in many different languages. </p>



<p>Until the volume of high-quality data for non-English languages gets much stronger — something that might slowly happen with more unstructured, private, and language-agnostic data in the next few years — CIOs need to demand better answers from model vendors on the training data for all non-English models.</p>



<p>Let’s say a global CIO is buying 118 models from an LLM vendor, in a wide range of languages. The CIO pays maybe $2 billion for the package. The vendor doesn’t tell the CIO how little training was done on all of those non-English models, and certainly not where that training data came from. If the vendors were fully transparent on both of those points, CIOs would push back on pricing for everything other than the English model. </p>



<p>In response, the model makers would likely not charge CIOs less for the non-English models but instead ramp up their efforts to find more training data to improve the accuracy of those models.</p>



<p>Given the massive amount of money enterprises are spending on genAI, the carrot is obvious. The stick? Maybe CIOs need to get out of their comfort zone and start buying their non-English models from regional vendors in every language they need. </p>



<p>If that starts to happen on a large scale, the major model makers may suddenly see the value of data-training transparency.</p>
</div></div></div></div>
  </div>
  <p>
    Sources:
    <span itemprop="author" itemscope itemtype="https://schema.org/Person">
      <a itemprop="url" href="https://www.computerworld.com/article/3810687/cios-grapple-with-subpar-global-genai-models.html" rel="external noreferrer nofollow noopener" target="_blank">
        <span itemprop="name">Computer World</span>
      </a>
    </span><br>
    Published:
    <span itemprop="datePublished">Feb 4, 2025, 6:00:00 AM EST</span>
  </p>
</div>
</main>
<footer>
  <div class="links">
    <a href="/terms/">Terms of Service</a> •
    <a href="/privacy/">Privacy Policy</a> •
    <a href="/disclaimer/">Disclaimer</a>
  </div>
  <div class="copy">
    <span class="icons" itemscope itemtype="https://schema.org/Organization">
      <meta itemprop="name" content="Major Digest">
      <meta itemprop="description" content="Reliable and Comprehensive News Sources">
      <meta itemprop="naics" content="513110">
      <link itemprop="url" href="https://majordigest.com/">
      <link itemprop="logo" href="https://majordigest.com/assets/icons/logo-512x512.png">
      <a href="https://x.com/major_digest/" rel="external" target="_blank" itemprop="sameAs" title="Follow us on X (Twitter)" aria-label="Follow us on X (Twitter)"><svg role="img" aria-label="X Logo" xmlns="http://www.w3.org/2000/svg" version="1.1" x="0px" y="0px" width="24px" height="24px" viewBox="0 0 312 312"><path d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66"/></svg></a>
      <a href="https://www.facebook.com/majordigest" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Facebook" aria-label="Follow us on Facebook"><svg role="img" aria-label="Facebook Logo" xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" x="0px" y="0px" viewBox="0 0 455.73 455.73"><path d="M0,0v455.73h242.704V279.691h-59.33v-71.864h59.33v-60.353c0-43.893,35.582-79.475,79.475-79.475h62.025v64.622h-44.382 c-13.947,0-25.254,11.307-25.254,25.254v49.953h68.521l-9.47,71.864h-59.051V455.73H455.73V0H0z"/></svg></a>
      <a href="https://www.instagram.com/majordigest" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Instagram" aria-label="Follow us on Instagram"><svg role="img" aria-label="Instagram Logo" xmlns="http://www.w3.org/2000/svg" version="1.1" x="0px" y="0px" width="24px" height="24px" viewBox="0 0 169.063 169.063"><path d="M122.406,0H46.654C20.929,0,0,20.93,0,46.655v75.752c0,25.726,20.929,46.655,46.654,46.655h75.752 c25.727,0,46.656-20.93,46.656-46.655V46.655C169.063,20.93,148.133,0,122.406,0z M154.063,122.407 c0,17.455-14.201,31.655-31.656,31.655H46.654C29.2,154.063,15,139.862,15,122.407V46.655C15,29.201,29.2,15,46.654,15h75.752 c17.455,0,31.656,14.201,31.656,31.655V122.407z"></path><path d="M84.531,40.97c-24.021,0-43.563,19.542-43.563,43.563c0,24.02,19.542,43.561,43.563,43.561s43.563-19.541,43.563-43.561 C128.094,60.512,108.552,40.97,84.531,40.97z M84.531,113.093c-15.749,0-28.563-12.812-28.563-28.561 c0-15.75,12.813-28.563,28.563-28.563s28.563,12.813,28.563,28.563C113.094,100.281,100.28,113.093,84.531,113.093z"></path><path d="M129.921,28.251c-2.89,0-5.729,1.17-7.77,3.22c-2.051,2.04-3.23,4.88-3.23,7.78c0,2.891,1.18,5.73,3.23,7.78 c2.04,2.04,4.88,3.22,7.77,3.22c2.9,0,5.73-1.18,7.78-3.22c2.05-2.05,3.22-4.89,3.22-7.78c0-2.9-1.17-5.74-3.22-7.78 C135.661,29.421,132.821,28.251,129.921,28.251z"></path></svg></a>
      <a href="https://www.threads.net/majordigest" rel="external" target="_blank" itemprop="sameAs"  title="Follow us on Threads" aria-label="Follow us on Threads"><svg role="img" aria-label="Threads Logo" width="24px" height="24px" viewBox="0 0 192 192" xmlns="http://www.w3.org/2000/svg"><path d="M141.537 88.9883C140.71 88.5919 139.87 88.2104 139.019 87.8451C137.537 60.5382 122.616 44.905 97.5619 44.745C97.4484 44.7443 97.3355 44.7443 97.222 44.7443C82.2364 44.7443 69.7731 51.1409 62.102 62.7807L75.881 72.2328C81.6116 63.5383 90.6052 61.6848 97.2286 61.6848C97.3051 61.6848 97.3819 61.6848 97.4576 61.6855C105.707 61.7381 111.932 64.1366 115.961 68.814C118.893 72.2193 120.854 76.925 121.825 82.8638C114.511 81.6207 106.601 81.2385 98.145 81.7233C74.3247 83.0954 59.0111 96.9879 60.0396 116.292C60.5615 126.084 65.4397 134.508 73.775 140.011C80.8224 144.663 89.899 146.938 99.3323 146.423C111.79 145.74 121.563 140.987 128.381 132.296C133.559 125.696 136.834 117.143 138.28 106.366C144.217 109.949 148.617 114.664 151.047 120.332C155.179 129.967 155.42 145.8 142.501 158.708C131.182 170.016 117.576 174.908 97.0135 175.059C74.2042 174.89 56.9538 167.575 45.7381 153.317C35.2355 139.966 29.8077 120.682 29.6052 96C29.8077 71.3178 35.2355 52.0336 45.7381 38.6827C56.9538 24.4249 74.2039 17.11 97.0132 16.9405C119.988 17.1113 137.539 24.4614 149.184 38.788C154.894 45.8136 159.199 54.6488 162.037 64.9503L178.184 60.6422C174.744 47.9622 169.331 37.0357 161.965 27.974C147.036 9.60668 125.202 0.195148 97.0695 0H96.9569C68.8816 0.19447 47.2921 9.6418 32.7883 28.0793C19.8819 44.4864 13.2244 67.3157 13.0007 95.9325L13 96L13.0007 96.0675C13.2244 124.684 19.8819 147.514 32.7883 163.921C47.2921 182.358 68.8816 191.806 96.9569 192H97.0695C122.03 191.827 139.624 185.292 154.118 170.811C173.081 151.866 172.51 128.119 166.26 113.541C161.776 103.087 153.227 94.5962 141.537 88.9883ZM98.4405 129.507C88.0005 130.095 77.1544 125.409 76.6196 115.372C76.2232 107.93 81.9158 99.626 99.0812 98.6368C101.047 98.5234 102.976 98.468 104.871 98.468C111.106 98.468 116.939 99.0737 122.242 100.233C120.264 124.935 108.662 128.946 98.4405 129.507Z"></path></svg></a>
      <a href="https://t.me/majordigest" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Telegram" aria-label="Follow us on Telegram"><svg role="img" aria-label="Telegram Logo" width="24px" height="24px" viewBox="0 0 48 48" xmlns="http://www.w3.org/2000/svg"><path fill="none" stroke="black" stroke-linecap="round" stroke-linejoin="round" d="M40.83,8.48c1.14,0,2,1,1.54,2.86l-5.58,26.3c-.39,1.87-1.52,2.32-3.08,1.45L20.4,29.26a.4.4,0,0,1,0-.65L35.77,14.73c.7-.62-.15-.92-1.07-.36L15.41,26.54a.46.46,0,0,1-.4.05L6.82,24C5,23.47,5,22.22,7.23,21.33L40,8.69a2.16,2.16,0,0,1,.83-.21Z"/></svg></a>
      <a href="https://www.youtube.com/@MajorDigest" rel="external" target="_blank" itemprop="sameAs" title="Follow us on YouTube" aria-label="Follow us on YouTube"><svg role="img" aria-label="YouTube Logo" height="24px" width="24px" version="1.1" viewBox="0 0 461.001 461.00" xmlns="http://www.w3.org/2000/svg"><path d="M365.257,67.393H95.744C42.866,67.393,0,110.259,0,163.137v134.728 c0,52.878,42.866,95.744,95.744,95.744h269.513c52.878,0,95.744-42.866,95.744-95.744V163.137 C461.001,110.259,418.135,67.393,365.257,67.393z M300.506,237.056l-126.06,60.123c-3.359,1.602-7.239-0.847-7.239-4.568V168.607 c0-3.774,3.982-6.22,7.348-4.514l126.06,63.881C304.363,229.873,304.298,235.248,300.506,237.056z"/></svg></a>
      <a href="https://podcasts.apple.com/us/podcast/major-digest-podcast/id1769748189" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Apple Podcasts" aria-label="Follow us on Apple Podcasts"><svg role="img" aria-label="Apple Podcasts Logo" width="21px" height="21px" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg></a>
      <a href="https://podcasters.spotify.com/pod/show/majordigest/" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Spotify" aria-label="Follow us on Spotify"><svg role="img" aria-label="Spotify Logo" width="28px" height="28px" viewBox="0 -2 30 30" version="1.1" xmlns="http://www.w3.org/2000/svg"><path d="M13.2 20.84c-0.2 0-0.4-0.080-0.56-0.2-1.84-1.6-5.8-1.12-7.2-0.84-0.44 0.12-0.92-0.2-1-0.64-0.12-0.44 0.2-0.88 0.64-1 0.24-0.040 5.8-1.24 8.64 1.2 0.36 0.32 0.4 0.84 0.080 1.2-0.12 0.16-0.36 0.28-0.6 0.28zM14.2 18.44c-0.16 0-0.32-0.040-0.48-0.16-3.36-2.4-8.48-1.080-8.52-1.080-0.44 0.12-0.92-0.16-1.040-0.6s0.16-0.92 0.6-1.040c0.24-0.080 5.92-1.56 9.96 1.32 0.36 0.28 0.48 0.8 0.2 1.16-0.2 0.28-0.44 0.4-0.72 0.4zM15.24 15.72c-0.16 0-0.32-0.040-0.48-0.16-4.44-2.96-10.040-1.040-10.12-1.040-0.44 0.16-0.88-0.080-1.040-0.52s0.080-0.92 0.52-1.080c0.28-0.080 6.48-2.2 11.6 1.24 0.4 0.24 0.48 0.76 0.24 1.16-0.2 0.24-0.48 0.4-0.72 0.4zM9.6 25.6c-5.28 0-9.6-4.32-9.6-9.6s4.32-9.6 9.6-9.6 9.6 4.32 9.6 9.6-4.32 9.6-9.6 9.6zM9.6 8.080c-4.36 0-7.92 3.56-7.92 7.92s3.56 7.92 7.92 7.92 7.92-3.56 7.92-7.92-3.56-7.92-7.92-7.92z"></path></svg></a>
<!--
      <a href="https://play.google.com/store/apps/details?id=com.majordigest.android" rel="external" target="_blank" itemprop="sameAs" title="Download Android App" aria-label="Download Android App"><svg role="img" aria-label="Google Play Logo" xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" x="0px" y="0px" viewBox="0 0 32 32"><path d="M20.331 14.644l-13.794-13.831 17.55 10.075zM2.938 0c-0.813 0.425-1.356 1.2-1.356 2.206v27.581c0 1.006 0.544 1.781 1.356 2.206l16.038-16zM29.512 14.1l-3.681-2.131-4.106 4.031 4.106 4.031 3.756-2.131c1.125-0.893 1.125-2.906-0.075-3.8zM6.538 31.188l17.55-10.075-3.756-3.756z"/></svg></a>
-->
    </span>
    © 2025&nbsp;<a href="/about/" title="About Major Digest: A Journey from Idea to Publication">Major Digest</a>
    <small> (v.1.1.6)</small>
  </div>
</footer>

<meta itemprop="operatingSystem" content="All">
<meta itemprop="applicationCategory" content="LifestyleApplication">
<meta itemprop="softwareVersion" content="1.1.6">
<div itemprop="offers" itemscope itemtype="https://schema.org/Offer">
  <meta itemprop="price" content="0">
  <meta itemprop="priceCurrency" content="USD">
</div>
<!--
<div itemprop="aggregateRating" itemscope itemtype="https://schema.org/AggregateRating">
  <meta itemprop="ratingValue" content="5">
  <meta itemprop="ratingCount" content="2">
  <link itemprop="sameAs" href="https://play.google.com/store/apps/details?id=com.majordigest.android">
</div>
<div itemprop="potentialAction" itemscope itemtype="https://schema.org/ViewAction">
  <meta itemprop="name" content="Open Major Digest">
  <link itemprop="target" href="https://majordigest.com/">
  <link itemprop="target" href="android-app://com.majordigest.android/http/majordigest.com">
</div>
<link rel="alternate" href="android-app://com.majordigest.android/http/majordigest.com">
-->

<section id="consent-banner" aria-label="Consent Banner" role="dialog">
  By continuing to use this app, you agree to our 
  <a href="/terms/">Terms of Service</a> and <a href="/privacy/">Privacy Policy</a>. 
  You can learn more about how we use cookies by reviewing our 
  <a href="/privacy/">Privacy Policy</a>. 
  <button onclick="this.parentNode.style.display='none'">Close</button>
</section>
<section id="ios-pwa-prompt" aria-label="iOS Installation Prompt" role="dialog">
  To install this app on your device tap
  <svg xmlns="http://www.w3.org/2000/svg" width="16px" viewBox="0 0 20.88 27.25">
    <polyline points="13.13 8 20.38 8 20.38 26.75 0.5 26.75 0.5 8 7.5 8"/>
    <line x1="10.44" y1="17" x2="10.44"/>
    <line x1="10.48" y1="0.38" x2="15.28" y2="5.18"/>
    <line x1="10.44" y1="0.38" x2="5.64" y2="5.18"/>
  </svg>
  and then Add to Home Screen.
  <button onclick="this.parentNode.style.display='none'">Close</button>
</section>
<script src="/assets/script.js?v=1.1.6" async></script>

<script type="application/ld+json">
{
   "@context": "https://schema.org/",
   "@type": "PodcastSeries",
   "image": "https://majordigest.com/assets/icons/logo-512x512.png",
   "url": "https://podcasters.spotify.com/pod/show/majordigest/",
   "name": "Major Digest Podcast - Spotify Podcasts",
   "description": "Your daily dose of tech news, straight to your feed. From AI and software development to emerging innovations, we’ve got you covered. Join our community of tech enthusiasts and industry professionals for daily updates on the future of technology.",
   "webFeed": "https://anchor.fm/s/fb28fbbc/podcast/rss",
   "author": {
     "@type": "Person",
     "name": "Major Digest"
   }
}
</script>
<script type="application/ld+json">
{
   "@context": "https://schema.org/",
   "@type": "PodcastSeries",
   "image": "https://majordigest.com/assets/icons/logo-512x512.png",
   "url": "https://podcasts.apple.com/us/podcast/major-digest-podcast/id1769748189",
   "name": "Major Digest Podcast - Apple Podcasts",
   "description": "Your daily dose of tech news, straight to your feed. From AI and software development to emerging innovations, we’ve got you covered. Join our community of tech enthusiasts and industry professionals for daily updates on the future of technology.",
   "webFeed": "https://anchor.fm/s/fb28fbbc/podcast/rss",
   "author": {
     "@type": "Person",
     "name": "Major Digest"
   }
}
</script>

</body>
</html>
