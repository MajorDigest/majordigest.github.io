<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" itemscope itemtype="https://schema.org/WebApplication" lang="en"
  prefix="og: https://ogp.me/ns#">

<head>
  <meta charset="utf-8">
  <title>This watchdog is tracking how AI firms are quietly backing off their safety pledges - Major Digest</title>
  <meta name="description" content="The companies racing to own the AI future have built their technologies and businesses by carefully keeping track of you and your data.">
  <link rel="canonical" href="https://majordigest.com/tech/2025/03/26/this-watchdog-is-tracking-how-ai-firms-are-quietly-backing-off-their-safety-pledges/">

  <meta itemprop="name" content="This watchdog is tracking how AI firms are quietly backing off their safety pledges - Major Digest">
  <meta itemprop="description" content="The companies racing to own the AI future have built their technologies and businesses by carefully keeping track of you and your data.">
  <link itemprop="url" href="https://majordigest.com/tech/2025/03/26/this-watchdog-is-tracking-how-ai-firms-are-quietly-backing-off-their-safety-pledges/">
  <meta itemprop="image" content="https://majordigest.com/static12/tech/2025/03/26/this-watchdog-is-tracking-how-ai-firms-are-quietly-backing-off-their-safety-pledges.webp">

  <meta property="og:title" content="This watchdog is tracking how AI firms are quietly backing off their safety pledges - Major Digest">
  <meta property="og:description" content="The companies racing to own the AI future have built their technologies and businesses by carefully keeping track of you and your data.">
  <meta property="og:url" content="https://majordigest.com/tech/2025/03/26/this-watchdog-is-tracking-how-ai-firms-are-quietly-backing-off-their-safety-pledges/">
  <meta property="og:image" content="https://majordigest.com/static12/tech/2025/03/26/this-watchdog-is-tracking-how-ai-firms-are-quietly-backing-off-their-safety-pledges.webp">
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="Major Digest">
  <meta property="og:locale" content="en_US">
  <meta property="fb:pages" content="113570554924596">
  <!-- <meta property="fb:app_id" content="490025408049997"> -->

  <meta name="twitter:title" content="This watchdog is tracking how AI firms are quietly backing off their safety pledges - Major Digest">
  <meta name="twitter:description" content="The companies racing to own the AI future have built their technologies and businesses by carefully keeping track of you and your data.">
  <meta name="twitter:url" content="https://majordigest.com/tech/2025/03/26/this-watchdog-is-tracking-how-ai-firms-are-quietly-backing-off-their-safety-pledges/">
  <meta name="twitter:image" content="https://majordigest.com/static12/tech/2025/03/26/this-watchdog-is-tracking-how-ai-firms-are-quietly-backing-off-their-safety-pledges.webp">
  <meta name="twitter:image:alt" content="This watchdog is tracking how AI firms are quietly backing off their safety pledges - Major Digest">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@major_digest">
  <meta name="twitter:creator" content="@vpodk">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=5.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-touch-icon.png">
  <link rel="apple-touch-startup-image" href="/assets/icons/logo-512x512.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
  <link rel="mask-icon" href="/assets/icons/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-status-bar-style" content="black">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="apple-mobile-web-app-title" content="Major Digest">
  <meta name="application-name" content="Major Digest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel="manifest" href="/manifest.json?v=1.1.6">
  <link rel="stylesheet" href="/assets/styles.css?v=1.1.6">
  <link rel="alternate" type="application/rss+xml" title="Major Digest RSS Feed"
    href="https://majordigest.com/tech/feed.xml">
  <link rel="sitemap" type="application/xml" title="Major Digest Sitemap"
    href="https://majordigest.com/tech/sitemap.xml">
</head>

<body class="tech">
  <a href="#main" class="skip-nav">Skip to Main Content</a>
  <header>
    <span>
      <time datetime="2025-03-26T13:59:49.005Z" itemprop="datePublished">Wednesday, March 26, 2025</time> &nbsp;
    </span>
    <h1>
      <a href="/" aria-label="Major Digest Home"><img src="/assets/logo.svg" alt="Major Digest Home" width="225"
          height="50"></a>
      <span>This watchdog is tracking how AI firms are quietly backing off their safety pledges - Major Digest</span>
    </h1>
  </header>
  <nav itemscope itemtype="https://schema.org/SiteNavigationElement">
    <a itemprop="url" href="/us/" title="The Latest U.S. News From Most Reliable Sources">U.S.</a>
    <a itemprop="url" href="/world/" title="Breaking News From Around the World">World</a>
    <a itemprop="url" href="/tech/" title="The Latest Tech News and Headlines">Technology</a>
    <a itemprop="url" href="/sports/" title="Stay Up to Date on Your Favorite Teams and Players">Sports</a>
    <a itemprop="url" href="/politics/" title="The Latest Political News and Headlines">Politics</a>
  </nav>
  <main id="main" aria-label="Main content">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
    "@type": "ListItem", "position": 1, "name": "Home",
    "item": "https://majordigest.com/"
  }, {
    "@type": "ListItem", "position": 2, "name": "tech",
    "item": "https://majordigest.com/tech/"
  }, {
    "@type": "ListItem", "position": 3, "name": "This watchdog is tracking how AI firms are quietly backing off their safety pledges - Major Digest"
  }]
}
</script>
<div itemscope itemtype="https://schema.org/NewsArticle" class="article">
  <meta itemprop="dateModified" content="Wed, 26 Mar 2025 16:00:00 GMT">
  <meta itemprop="url" content="/tech/2025/03/26/this-watchdog-is-tracking-how-ai-firms-are-quietly-backing-off-their-safety-pledges/">
  <h2 itemprop="headline">This watchdog is tracking how AI firms are quietly backing off their safety pledges</h2>
  <div itemprop="articleBody">
    <figure>
      <img src="/static12/tech/2025/03/26/this-watchdog-is-tracking-how-ai-firms-are-quietly-backing-off-their-safety-pledges.webp" alt="This watchdog is tracking how AI firms are quietly backing off their safety pledges" itemprop="image" width="400" height="225"
        data-src="https://images.fastcompany.com/image/upload/w_1280,q_auto,f_auto,fl_lossy/f_webp,q_auto,c_fit/wp-cms-2/2025/03/p-1-91304014-this-watchdog-is-tracking-how-ai-firms-are-quietly-backing-off-their-safety-pledges.jpg">
      <figcaption>Credit: Jackie Snow, Fast Company</figcaption>
    </figure>
    
<p>The companies racing to own the AI future have built their technologies and businesses by carefully keeping track of you and your data. But they would prefer you didn&#8217;t keep track of them and specifically the ways in which they&#8217;ve been adjusting their voluntary ethical and privacy commitments—some of the few safeguards meant to keep that AI future safe. </p>



<p>As the Trump administration actively dismantles safety guardrails to promote &#8220;American dominance&#8221; in AI and companies disband their safety teams, it&#8217;s fallen to a tiny nonprofit with limited resources to track how these trillion-dollar companies are adjusting their policies and honoring their own ethical commitments.</p>



<p>Tyler Johnston and his group, the Midas Project, have become the digital world&#8217;s equivalent of a one-person fire department, trying to monitor a forest of potential blazes. Launched in mid-2024, the nonprofit&#8217;s &#8220;AI Safety Watchtower&#8221; project now tracks 16 companies—including OpenAI, Google, and Anthropic—to monitor hundreds of policy documents and web pages for changes. </p>



<p>&#8220;If every AI company had a change log, this work would be unnecessary,” says Johnston. “That would be the ultimate transparency. Instead, it&#8217;s up to nonprofits and journalists to monitor this, and nobody&#8217;s well-equipped enough to catch all of it.&#8221;</p>



<p>Johnston’s concerns about abandoned safety commitments come as the Trump administration actively dismantles AI safety guardrails. On his second day in office this term, Trump signed an executive order revoking Biden&#8217;s 2023 AI safety order, replacing it with one focused on &#8220;American dominance&#8221; in AI. In March, the National Institute of Standards and Technology issued new directives to scientists at the Artificial Intelligence Safety Institute that eliminated mentions of &#8220;AI safety, responsible AI,&#8221; and &#8220;AI fairness.&#8221; </p>



<p>While various states have taken steps to pass AI regulation and bills have been proposed on Capitol Hill, there are as yet no federal rules specifically governing the use of the technology. In recent weeks, Trump’s Office of Science and Technology Policy solicited public comments from companies, academics, and others for a forthcoming &#8220;AI action plan&#8221;; Silicon Valley, not surprisingly, has urged a light regulatory touch. </p>



<p>Johnston came to AI ethics from animal welfare advocacy, where targeted campaigns successfully pushed food companies to adopt cage-free-egg practices. He hoped to replicate that success by becoming the &#8220;bad cop&#8221; willing to pressure tech giants. </p>



<p>With about 1,500 followers across two X accounts, Johnston runs Midas Project full time, with Safety Watchtower taking up about 5% of his time. The group is run on a shoestring budget, so he’s DIYing a lot for now, with some help from volunteers.</p>



<p>Johnston isn&#8217;t backed by billions in venture capital or government funding—just determination and a basic web-scraping tool that detects when companies quietly delete promises about not building killer robots or enabling bioweapons development.&nbsp;</p>



<p>So far, the Watchtower has documented about 30 significant changes, categorizing them by the tags major, slight, and unannounced. The first being OpenAI’s “slight” modification of its “core values” in October 2023. OpenAI removed values such as “impact-driven,” which emphasized that employees “care deeply about real-world implications,” replacing them with values such as “AGI focus.” </p>



<p>Another “slight” policy change caught by AI Watchtower came from Meta in June 2024, when it made explicit that it can use data from Facebook, Whatsapp, and Instagram to change its model.</p>



<p>The Watchtower also flagged a “major” change by Google last month when the company released a new version of its Frontier Safety Framework. Johnston&#8217;s analysis revealed concerning modifications: model autonomy risks were removed and replaced with vaguely defined &#8220;alignment risks,&#8221; and notably, the company added language suggesting it would only follow its framework if competitors adopted similar measures.</p>



<p>At times, companies have responded to Johnston&#8217;s alerts. Earlier this month, Watchtower&#8217;s web scrapers noticed that Anthropic removed references to the &#8220;White House&#8217;s Voluntary Commitments for Safe, Secure, and Trustworthy AI&#8221; from its Transparency Hub webpage. But Anthropic cofounder Jack Clark clarified on X: &#8220;This isn&#8217;t a change in substance and has caused some confusion—we&#8217;re working on a fix. We continue to follow the White House Voluntary Commitments.&#8221;</p>



<p>The status of these commitments under the Trump Administration remains unclear. The commitments were independent promises companies made to the Biden White House and the public about managing AI risks, meaning they shouldn&#8217;t be affected by Trump’s executive order rolling back Biden’s AI policies.</p>



<p>Several companies including Nvidia, Inflection, and Scale AI confirmed they’re still adhering to the commitments post-election, according to FedScoop. Anthropic eventually restored the reference to its website but added a curious disclaimer: “Though these specific commitments are no longer formally maintained under the Trump administration, our organization continues to uphold all these principles.” The White House did not respond to a request for clarification.</p>



<p>In another case, a commitment flagged as removed from Anthropic&#8217;s website had simply been relocated to a different page. For Johnston, this highlights a broader issue with transparency in the industry: the companies, not journalists, should be clear about how and when their policies are changing.</p>



<p>The most consequential shift Johnston has documented is AI companies reversing their military stances. According to Johnston, OpenAI&#8217;s reversal was particularly calculating—initially framed as helping prevent veteran suicide and supporting Pentagon cybersecurity. Critics were painted as heartless for questioning this work but by November 2024, OpenAI was developing autonomous drones in what Johnston described as a classic foot-in-the-door strategy. Google followed suit earlier this year, revoking its own military restrictions. </p>



<p>&#8220;A lot of them are starting to really feel the global [AI] race dynamic,&#8221; Johnston says. &#8220;They&#8217;re like, &#8216;Well, we have to do this because if we don&#8217;t work with militaries, less scrupulous actors will.'&#8221;</p>



<p>The military pivot is just one example of how AI companies are reframing their ethical stances. OpenAI recently published a document outlining its philosophy on AI safety, claiming it has moved beyond the more cautious &#8220;staged deployment&#8221; approach it took with GPT-2 in 2019, when it initially withheld release citing safety concerns. </p>



<p>“In a discontinuous world, practicing for the AGI moment is the only thing we can do, and safety lessons come from treating the systems of today with outsize caution relative to their apparent power. This is the approach we took for GPT‑2,” OpenAI wrote.</p>



<p>But Miles Brundage, OpenAI&#8217;s former head of policy research, publicly challenged this characterization, saying the company was rewriting the “history of GPT-2 in a concerning way.”</p>



<p>&#8220;OpenAI&#8217;s release of GPT-2, which I was involved in, was 100% consistent with OpenAI&#8217;s current philosophy of iterative deployment,&#8221; Brundage wrote on X. &#8220;The model was released incrementally, with lessons shared at each step. Many security experts at the time thanked us for this caution.&#8221;</p>



<p>Brundage fears OpenAI is now setting up a framework where &#8220;concerns are alarmist&#8221; and &#8220;you need overwhelming evidence of imminent dangers to act on them&#8221;—a mentality he calls &#8220;very dangerous&#8221; for advanced AI systems.</p>



<p>The pattern of changes extends beyond the companies&#8217; own rules and policies. In February, Johnston&#8217;s team launched &#8220;Seoul Tracker&#8221; to evaluate whether companies were honoring promises made at the 2024 AI Safety Summit in Seoul. The results were damning: Many simply ignored the February deadline for adopting responsible scaling policies, while others implemented hollow versions that barely resembled what they&#8217;d promised. </p>



<p>Using a letter-grade scoring system based on public evidence of implementation across five key commitment areas, the Seoul Tracker gave Anthropic the highest score, a B-, while companies including IBM, Inflection AI, and Mistral AI received failing grades of F for showing no public evidence that they had fulfilled their commitments.</p>



<p>&#8220;It&#8217;s wild to me,&#8221; Johnston says. &#8220;These were promises they made not just on some webpage, but to the governments of the United Kingdom and South Korea.&#8221;</p>



<p>Perhaps what&#8217;s perhaps most telling about the impact of Johnston&#8217;s work is who&#8217;s paying attention. While Midas Project struggles to get 500 signatures on petitions to ask AI companies to take security seriously, and its follower count is still relatively modest, those followers include plenty of the who&#8217;s who of AI luminaries, watchdogs, and whistleblowers. </p>



<p>Even a Trump White House advisor on AI recently followed the account, too. That got Johnston wondering whether government officials view these ethical reversals as progress rather than problems.</p>



<p>“I&#8217;m so worried that he&#8217;s following it like cheering it on,” he says, “seeing the changes as wins as these companies abandon their commitments.”</p> 

  </div>
  <p>
    Sources:
    <span itemprop="author" itemscope itemtype="https://schema.org/Person">
      <a itemprop="url" href="https://www.fastcompany.com/91304014/this-watchdog-is-tracking-how-ai-firms-are-quietly-backing-off-their-safety-pledges?partner=rss&amp%3Butm_source=rss&amp%3Butm_medium=feed&amp%3Butm_campaign=rss+fastcompany&amp%3Butm_content=rss" rel="external noreferrer nofollow noopener" target="_blank">
        <span itemprop="name">Jackie Snow, Fast Company</span>
      </a>
    </span><br>
    Published:
    <span itemprop="datePublished">Mar 26, 2025, 12:00:00 PM EDT</span>
  </p>
</div>
</main>
<footer>
  <div class="links">
    <a href="/terms/">Terms of Service</a> •
    <a href="/privacy/">Privacy Policy</a> •
    <a href="/disclaimer/">Disclaimer</a>
  </div>
  <div class="copy">
    <span class="icons" itemscope itemtype="https://schema.org/Organization">
      <meta itemprop="name" content="Major Digest">
      <meta itemprop="description" content="Reliable and Comprehensive News Sources">
      <meta itemprop="naics" content="513110">
      <link itemprop="url" href="https://majordigest.com/">
      <link itemprop="logo" href="https://majordigest.com/assets/icons/logo-512x512.png">
      <a href="https://x.com/major_digest/" rel="external" target="_blank" itemprop="sameAs" title="Follow us on X (Twitter)" aria-label="Follow us on X (Twitter)"><svg role="img" aria-label="X Logo" xmlns="http://www.w3.org/2000/svg" version="1.1" x="0px" y="0px" width="24px" height="24px" viewBox="0 0 312 312"><path d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66"/></svg></a>
      <a href="https://www.facebook.com/majordigest" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Facebook" aria-label="Follow us on Facebook"><svg role="img" aria-label="Facebook Logo" xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" x="0px" y="0px" viewBox="0 0 455.73 455.73"><path d="M0,0v455.73h242.704V279.691h-59.33v-71.864h59.33v-60.353c0-43.893,35.582-79.475,79.475-79.475h62.025v64.622h-44.382 c-13.947,0-25.254,11.307-25.254,25.254v49.953h68.521l-9.47,71.864h-59.051V455.73H455.73V0H0z"/></svg></a>
      <a href="https://www.instagram.com/majordigest" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Instagram" aria-label="Follow us on Instagram"><svg role="img" aria-label="Instagram Logo" xmlns="http://www.w3.org/2000/svg" version="1.1" x="0px" y="0px" width="24px" height="24px" viewBox="0 0 169.063 169.063"><path d="M122.406,0H46.654C20.929,0,0,20.93,0,46.655v75.752c0,25.726,20.929,46.655,46.654,46.655h75.752 c25.727,0,46.656-20.93,46.656-46.655V46.655C169.063,20.93,148.133,0,122.406,0z M154.063,122.407 c0,17.455-14.201,31.655-31.656,31.655H46.654C29.2,154.063,15,139.862,15,122.407V46.655C15,29.201,29.2,15,46.654,15h75.752 c17.455,0,31.656,14.201,31.656,31.655V122.407z"></path><path d="M84.531,40.97c-24.021,0-43.563,19.542-43.563,43.563c0,24.02,19.542,43.561,43.563,43.561s43.563-19.541,43.563-43.561 C128.094,60.512,108.552,40.97,84.531,40.97z M84.531,113.093c-15.749,0-28.563-12.812-28.563-28.561 c0-15.75,12.813-28.563,28.563-28.563s28.563,12.813,28.563,28.563C113.094,100.281,100.28,113.093,84.531,113.093z"></path><path d="M129.921,28.251c-2.89,0-5.729,1.17-7.77,3.22c-2.051,2.04-3.23,4.88-3.23,7.78c0,2.891,1.18,5.73,3.23,7.78 c2.04,2.04,4.88,3.22,7.77,3.22c2.9,0,5.73-1.18,7.78-3.22c2.05-2.05,3.22-4.89,3.22-7.78c0-2.9-1.17-5.74-3.22-7.78 C135.661,29.421,132.821,28.251,129.921,28.251z"></path></svg></a>
      <a href="https://www.threads.net/majordigest" rel="external" target="_blank" itemprop="sameAs"  title="Follow us on Threads" aria-label="Follow us on Threads"><svg role="img" aria-label="Threads Logo" width="24px" height="24px" viewBox="0 0 192 192" xmlns="http://www.w3.org/2000/svg"><path d="M141.537 88.9883C140.71 88.5919 139.87 88.2104 139.019 87.8451C137.537 60.5382 122.616 44.905 97.5619 44.745C97.4484 44.7443 97.3355 44.7443 97.222 44.7443C82.2364 44.7443 69.7731 51.1409 62.102 62.7807L75.881 72.2328C81.6116 63.5383 90.6052 61.6848 97.2286 61.6848C97.3051 61.6848 97.3819 61.6848 97.4576 61.6855C105.707 61.7381 111.932 64.1366 115.961 68.814C118.893 72.2193 120.854 76.925 121.825 82.8638C114.511 81.6207 106.601 81.2385 98.145 81.7233C74.3247 83.0954 59.0111 96.9879 60.0396 116.292C60.5615 126.084 65.4397 134.508 73.775 140.011C80.8224 144.663 89.899 146.938 99.3323 146.423C111.79 145.74 121.563 140.987 128.381 132.296C133.559 125.696 136.834 117.143 138.28 106.366C144.217 109.949 148.617 114.664 151.047 120.332C155.179 129.967 155.42 145.8 142.501 158.708C131.182 170.016 117.576 174.908 97.0135 175.059C74.2042 174.89 56.9538 167.575 45.7381 153.317C35.2355 139.966 29.8077 120.682 29.6052 96C29.8077 71.3178 35.2355 52.0336 45.7381 38.6827C56.9538 24.4249 74.2039 17.11 97.0132 16.9405C119.988 17.1113 137.539 24.4614 149.184 38.788C154.894 45.8136 159.199 54.6488 162.037 64.9503L178.184 60.6422C174.744 47.9622 169.331 37.0357 161.965 27.974C147.036 9.60668 125.202 0.195148 97.0695 0H96.9569C68.8816 0.19447 47.2921 9.6418 32.7883 28.0793C19.8819 44.4864 13.2244 67.3157 13.0007 95.9325L13 96L13.0007 96.0675C13.2244 124.684 19.8819 147.514 32.7883 163.921C47.2921 182.358 68.8816 191.806 96.9569 192H97.0695C122.03 191.827 139.624 185.292 154.118 170.811C173.081 151.866 172.51 128.119 166.26 113.541C161.776 103.087 153.227 94.5962 141.537 88.9883ZM98.4405 129.507C88.0005 130.095 77.1544 125.409 76.6196 115.372C76.2232 107.93 81.9158 99.626 99.0812 98.6368C101.047 98.5234 102.976 98.468 104.871 98.468C111.106 98.468 116.939 99.0737 122.242 100.233C120.264 124.935 108.662 128.946 98.4405 129.507Z"></path></svg></a>
      <a href="https://t.me/majordigest" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Telegram" aria-label="Follow us on Telegram"><svg role="img" aria-label="Telegram Logo" width="24px" height="24px" viewBox="0 0 48 48" xmlns="http://www.w3.org/2000/svg"><path fill="none" stroke="black" stroke-linecap="round" stroke-linejoin="round" d="M40.83,8.48c1.14,0,2,1,1.54,2.86l-5.58,26.3c-.39,1.87-1.52,2.32-3.08,1.45L20.4,29.26a.4.4,0,0,1,0-.65L35.77,14.73c.7-.62-.15-.92-1.07-.36L15.41,26.54a.46.46,0,0,1-.4.05L6.82,24C5,23.47,5,22.22,7.23,21.33L40,8.69a2.16,2.16,0,0,1,.83-.21Z"/></svg></a>
<!--
      <a href="https://www.youtube.com/@MajorDigest" rel="external" target="_blank" itemprop="sameAs" title="Follow us on YouTube" aria-label="Follow us on YouTube"><svg role="img" aria-label="YouTube Logo" height="24px" width="24px" version="1.1" viewBox="0 0 461.001 461.00" xmlns="http://www.w3.org/2000/svg"><path d="M365.257,67.393H95.744C42.866,67.393,0,110.259,0,163.137v134.728 c0,52.878,42.866,95.744,95.744,95.744h269.513c52.878,0,95.744-42.866,95.744-95.744V163.137 C461.001,110.259,418.135,67.393,365.257,67.393z M300.506,237.056l-126.06,60.123c-3.359,1.602-7.239-0.847-7.239-4.568V168.607 c0-3.774,3.982-6.22,7.348-4.514l126.06,63.881C304.363,229.873,304.298,235.248,300.506,237.056z"/></svg></a>
      <a href="https://podcasts.apple.com/us/podcast/major-digest-podcast/id1769748189" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Apple Podcasts" aria-label="Follow us on Apple Podcasts"><svg role="img" aria-label="Apple Podcasts Logo" width="21px" height="21px" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg></a>
      <a href="https://podcasters.spotify.com/pod/show/majordigest/" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Spotify" aria-label="Follow us on Spotify"><svg role="img" aria-label="Spotify Logo" width="28px" height="28px" viewBox="0 -2 30 30" version="1.1" xmlns="http://www.w3.org/2000/svg"><path d="M13.2 20.84c-0.2 0-0.4-0.080-0.56-0.2-1.84-1.6-5.8-1.12-7.2-0.84-0.44 0.12-0.92-0.2-1-0.64-0.12-0.44 0.2-0.88 0.64-1 0.24-0.040 5.8-1.24 8.64 1.2 0.36 0.32 0.4 0.84 0.080 1.2-0.12 0.16-0.36 0.28-0.6 0.28zM14.2 18.44c-0.16 0-0.32-0.040-0.48-0.16-3.36-2.4-8.48-1.080-8.52-1.080-0.44 0.12-0.92-0.16-1.040-0.6s0.16-0.92 0.6-1.040c0.24-0.080 5.92-1.56 9.96 1.32 0.36 0.28 0.48 0.8 0.2 1.16-0.2 0.28-0.44 0.4-0.72 0.4zM15.24 15.72c-0.16 0-0.32-0.040-0.48-0.16-4.44-2.96-10.040-1.040-10.12-1.040-0.44 0.16-0.88-0.080-1.040-0.52s0.080-0.92 0.52-1.080c0.28-0.080 6.48-2.2 11.6 1.24 0.4 0.24 0.48 0.76 0.24 1.16-0.2 0.24-0.48 0.4-0.72 0.4zM9.6 25.6c-5.28 0-9.6-4.32-9.6-9.6s4.32-9.6 9.6-9.6 9.6 4.32 9.6 9.6-4.32 9.6-9.6 9.6zM9.6 8.080c-4.36 0-7.92 3.56-7.92 7.92s3.56 7.92 7.92 7.92 7.92-3.56 7.92-7.92-3.56-7.92-7.92-7.92z"></path></svg></a>
      <a href="https://play.google.com/store/apps/details?id=com.majordigest.android" rel="external" target="_blank" itemprop="sameAs" title="Download Android App" aria-label="Download Android App"><svg role="img" aria-label="Google Play Logo" xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" x="0px" y="0px" viewBox="0 0 32 32"><path d="M20.331 14.644l-13.794-13.831 17.55 10.075zM2.938 0c-0.813 0.425-1.356 1.2-1.356 2.206v27.581c0 1.006 0.544 1.781 1.356 2.206l16.038-16zM29.512 14.1l-3.681-2.131-4.106 4.031 4.106 4.031 3.756-2.131c1.125-0.893 1.125-2.906-0.075-3.8zM6.538 31.188l17.55-10.075-3.756-3.756z"/></svg></a>
-->
    </span>
    © 2025&nbsp;<a href="/about/" title="About Major Digest: A Journey from Idea to Publication">Major Digest</a>
    <small> (v.1.1.6)</small>
  </div>
</footer>

<meta itemprop="operatingSystem" content="All">
<meta itemprop="applicationCategory" content="LifestyleApplication">
<meta itemprop="softwareVersion" content="1.1.6">
<div itemprop="offers" itemscope itemtype="https://schema.org/Offer">
  <meta itemprop="price" content="0">
  <meta itemprop="priceCurrency" content="USD">
</div>
<!--
<div itemprop="aggregateRating" itemscope itemtype="https://schema.org/AggregateRating">
  <meta itemprop="ratingValue" content="5">
  <meta itemprop="ratingCount" content="2">
  <link itemprop="sameAs" href="https://play.google.com/store/apps/details?id=com.majordigest.android">
</div>
<div itemprop="potentialAction" itemscope itemtype="https://schema.org/ViewAction">
  <meta itemprop="name" content="Open Major Digest">
  <link itemprop="target" href="https://majordigest.com/">
  <link itemprop="target" href="android-app://com.majordigest.android/http/majordigest.com">
</div>
<link rel="alternate" href="android-app://com.majordigest.android/http/majordigest.com">
-->

<section id="consent-banner" aria-label="Consent Banner" role="dialog">
  By continuing to use this app, you agree to our 
  <a href="/terms/">Terms of Service</a> and <a href="/privacy/">Privacy Policy</a>. 
  You can learn more about how we use cookies by reviewing our 
  <a href="/privacy/">Privacy Policy</a>. 
  <button onclick="this.parentNode.style.display='none'">Close</button>
</section>
<section id="ios-pwa-prompt" aria-label="iOS Installation Prompt" role="dialog">
  To install this app on your device tap
  <svg xmlns="http://www.w3.org/2000/svg" width="16px" viewBox="0 0 20.88 27.25">
    <polyline points="13.13 8 20.38 8 20.38 26.75 0.5 26.75 0.5 8 7.5 8"/>
    <line x1="10.44" y1="17" x2="10.44"/>
    <line x1="10.48" y1="0.38" x2="15.28" y2="5.18"/>
    <line x1="10.44" y1="0.38" x2="5.64" y2="5.18"/>
  </svg>
  and then Add to Home Screen.
  <button onclick="this.parentNode.style.display='none'">Close</button>
</section>
<script src="/assets/script.js?v=1.1.6" async></script>

<script type="application/ld+json">
{
   "@context": "https://schema.org/",
   "@type": "PodcastSeries",
   "image": "https://majordigest.com/assets/icons/logo-512x512.png",
   "url": "https://podcasters.spotify.com/pod/show/majordigest/",
   "name": "Major Digest Podcast - Spotify Podcasts",
   "description": "Your daily dose of tech news, straight to your feed. From AI and software development to emerging innovations, we’ve got you covered. Join our community of tech enthusiasts and industry professionals for daily updates on the future of technology.",
   "webFeed": "https://anchor.fm/s/fb28fbbc/podcast/rss",
   "author": {
     "@type": "Person",
     "name": "Major Digest"
   }
}
</script>
<script type="application/ld+json">
{
   "@context": "https://schema.org/",
   "@type": "PodcastSeries",
   "image": "https://majordigest.com/assets/icons/logo-512x512.png",
   "url": "https://podcasts.apple.com/us/podcast/major-digest-podcast/id1769748189",
   "name": "Major Digest Podcast - Apple Podcasts",
   "description": "Your daily dose of tech news, straight to your feed. From AI and software development to emerging innovations, we’ve got you covered. Join our community of tech enthusiasts and industry professionals for daily updates on the future of technology.",
   "webFeed": "https://anchor.fm/s/fb28fbbc/podcast/rss",
   "author": {
     "@type": "Person",
     "name": "Major Digest"
   }
}
</script>

</body>
</html>
