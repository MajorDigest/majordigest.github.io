<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" itemscope itemtype="https://schema.org/WebApplication" lang="en"
  prefix="og: https://ogp.me/ns#">

<head>
  <meta charset="utf-8">
  <title>Spring AI tutorial: Get started with Spring AI - Major Digest</title>
  <meta name="description" content="Artificial intelligence and related technologies are evolving rapidly, but until recently, Java developers had few options for integrating AI capabilities directly into Spring-based applications.">
  <link rel="canonical" href="https://majordigest.com/tech/2025/12/04/spring-ai-tutorial-get-started-with-spring-ai/">

  <meta itemprop="name" content="Spring AI tutorial: Get started with Spring AI - Major Digest">
  <meta itemprop="description" content="Artificial intelligence and related technologies are evolving rapidly, but until recently, Java developers had few options for integrating AI capabilities directly into Spring-based applications.">
  <link itemprop="url" href="https://majordigest.com/tech/2025/12/04/spring-ai-tutorial-get-started-with-spring-ai/">
  <meta itemprop="image" content="https://majordigest.com/static13/tech/2025/12/04/spring-ai-tutorial-get-started-with-spring-ai.webp">

  <meta property="og:title" content="Spring AI tutorial: Get started with Spring AI - Major Digest">
  <meta property="og:description" content="Artificial intelligence and related technologies are evolving rapidly, but until recently, Java developers had few options for integrating AI capabilities directly into Spring-based applications.">
  <meta property="og:url" content="https://majordigest.com/tech/2025/12/04/spring-ai-tutorial-get-started-with-spring-ai/">
  <meta property="og:image" content="https://majordigest.com/static13/tech/2025/12/04/spring-ai-tutorial-get-started-with-spring-ai.webp">
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="Major Digest">
  <meta property="og:locale" content="en_US">
  <meta property="fb:pages" content="113570554924596">
  <!-- <meta property="fb:app_id" content="490025408049997"> -->

  <meta name="twitter:title" content="Spring AI tutorial: Get started with Spring AI - Major Digest">
  <meta name="twitter:description" content="Artificial intelligence and related technologies are evolving rapidly, but until recently, Java developers had few options for integrating AI capabilities directly into Spring-based applications.">
  <meta name="twitter:url" content="https://majordigest.com/tech/2025/12/04/spring-ai-tutorial-get-started-with-spring-ai/">
  <meta name="twitter:image" content="https://majordigest.com/static13/tech/2025/12/04/spring-ai-tutorial-get-started-with-spring-ai.webp">
  <meta name="twitter:image:alt" content="Spring AI tutorial: Get started with Spring AI - Major Digest">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@major_digest">
  <meta name="twitter:creator" content="@vpodk">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=5.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-touch-icon.png">
  <link rel="apple-touch-startup-image" href="/assets/icons/logo-512x512.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
  <link rel="mask-icon" href="/assets/icons/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-status-bar-style" content="black">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="apple-mobile-web-app-title" content="Major Digest">
  <meta name="application-name" content="Major Digest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel="manifest" href="/manifest.json?v=1.1.6">
  <link rel="stylesheet" href="/assets/styles.css?v=1.1.6">
  <link rel="alternate" type="application/rss+xml" title="Major Digest RSS Feed"
    href="https://majordigest.com/tech/feed.xml">
  <link rel="sitemap" type="application/xml" title="Major Digest Sitemap"
    href="https://majordigest.com/tech/sitemap.xml">
</head>

<body class="tech">
  <a href="#main" class="skip-nav">Skip to Main Content</a>
  <header>
    <span>
      <time datetime="2025-12-04T14:00:50.836Z" itemprop="datePublished">Thursday, December 4, 2025</time> &nbsp;
    </span>
    <h1>
      <a href="/" aria-label="Major Digest Home"><img src="/assets/logo.svg" alt="Major Digest Home" width="225"
          height="50"></a>
      <span>Spring AI tutorial: Get started with Spring AI - Major Digest</span>
    </h1>
  </header>
  <nav itemscope itemtype="https://schema.org/SiteNavigationElement">
    <a itemprop="url" href="/us/" title="The Latest U.S. News From Most Reliable Sources">U.S.</a>
    <a itemprop="url" href="/world/" title="Breaking News From Around the World">World</a>
    <a itemprop="url" href="/tech/" title="The Latest Tech News and Headlines">Technology</a>
    <a itemprop="url" href="/sports/" title="Stay Up to Date on Your Favorite Teams and Players">Sports</a>
    <a itemprop="url" href="/politics/" title="The Latest Political News and Headlines">Politics</a>
  </nav>
  <main id="main" aria-label="Main content">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
    "@type": "ListItem", "position": 1, "name": "Home",
    "item": "https://majordigest.com/"
  }, {
    "@type": "ListItem", "position": 2, "name": "tech",
    "item": "https://majordigest.com/tech/"
  }, {
    "@type": "ListItem", "position": 3, "name": "Spring AI tutorial: Get started with Spring AI - Major Digest"
  }]
}
</script>
<div itemscope itemtype="https://schema.org/NewsArticle" class="article">
  <meta itemprop="dateModified" content="Thu, 04 Dec 2025 09:00:00 GMT">
  <meta itemprop="url" content="/tech/2025/12/04/spring-ai-tutorial-get-started-with-spring-ai/">
  <h2 itemprop="headline">Spring AI tutorial: Get started with Spring AI</h2>
  <div itemprop="articleBody">
    <figure>
      <img src="/static13/tech/2025/12/04/spring-ai-tutorial-get-started-with-spring-ai.webp" alt="Spring AI tutorial: Get started with Spring AI" itemprop="image" width="400" height="225"
        data-src="https://www.infoworld.com/wp-content/uploads/2025/12/4091447-0-68712100-1764838912-green-leaves-sprouting-photo-by-francesco-gallarotti-via-unsplash-100940892-orig.jpg?quality=50&strip=all">
      <figcaption>Credit: Info World</figcaption>
    </figure>
    <div id="remove_no_follow">
		<div class="grid grid--cols-10@md grid--cols-8@lg article-column">
					  <div class="col-12 col-10@md col-6@lg col-start-3@lg">
						<div class="article-column__content">
<section class="wp-block-bigbite-multi-title"><div class="container"></div></section>



<p>Artificial intelligence and related technologies are evolving rapidly, but until recently, Java developers had few options for integrating AI capabilities directly into Spring-based applications. Spring AI changes that by leveraging familiar Spring conventions such as dependency injection and the configuration-first philosophy in a modern AI development framework.</p>



<p>In this article, you will learn how to integrate AI into your Spring applications. We’ll start with a simple example that sends a request to OpenAI, then use Spring AI’s prompt templates to add support for user-generated queries. You’ll also get a first look at implementing retrieval augmented generation (RAG) with Spring AI, using a vector store to manage external documents.</p>



<h3 class="wp-block-heading" id="what-is-spring-ai">What is Spring AI?</h3>



<p>Spring AI started as a project in 2023, with its first milestone version released in early 2024. Spring AI 1.0, the general availability release, was finalized in May 2025. Spring AI abstracts the processes involved in interacting with large language models (LLMs), similar to how Spring Data abstracts database access procedures. Spring AI also provides abstractions for managing prompts, selecting models, and handing AI responses. It includes support for multiple AI providers, including OpenAI, Anthropic, Hugging Face, and Ollama (for local LLMs).</p>



<p>Spring AI allows you to easily switch between providers simply by changing configuration properties. As a developer, you configure your AI resources in your <code>application.yaml</code> or <code>application.properties</code> file, wire in Spring beans that provide standard interfaces, and write your code against those interfaces. Spring then handles all the details of interacting with the specific models.</p>



<p><strong>Also see: Spring AI: An AI framework for Java developers.</strong></p>



<h3 class="wp-block-heading" id="building-a-spring-app-that-queries-openai">Building a Spring app that queries OpenAI</h3>



<p>Let’s start by building a simple Spring MVC application that exposes a query endpoint, which sends a question to OpenAI. You can download the source code for this example or head over to <code>start.spring.io</code> and create a new project. In the dependencies section, include the dependencies you want for your application; just be sure to scroll down to the AI section and choose “OpenAI.” I chose “Spring Web” and “OpenAI” for my example.</p>



<p>The first thing we want to do is configure our LLM provider. I created an <code>application.yaml</code> file with the following contents:</p>



<pre class="wp-block-code"><code>spring:
  application:
    name: spring-ai-demo
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      chat:
        options:
          model: gpt-5
          temperature: 1</code></pre>



<p>Under <code>spring</code>, I included an “<code>ai</code>” section, with an “<code>openai</code>” subsection. To use OpenAI, you need to specify an <code>api-key</code>, which I defined to use the <code>OPENAI_API_KEY</code> environment variable, so be sure to define that environment variable before running the example code. Additionally, you need to specify a set of options. The most important option is the model to use. I chose <code>gpt-5</code>, but you can choose any model listed on the OpenAI models page. By default, Spring AI uses gpt-4o-mini, which is less expensive, but <code>gpt-5</code> supports structured reasoning, multi-step logic, planning, and more tokens. It doesn’t really matter which model we use for this example, but I wanted to show you how to configure the model.</p>



<p>There are several other configuration options, but the most common ones you’ll use are <code>maxTokens</code>, <code>maxCompletionTokens</code>, and <code>temperature</code>. The <em>temperature</em> controls the randomness of the response, where a low value, like 0.3, provides a more repeatable response and a higher value, like 0.7 allows the LLM to be more creative. When I ask a model to design a software component or perform a code review, I typically opt for a higher temperature of 0.7 because I want it to be more creative, but when I ask it to implement the code for a project, I set the temperature to 0.3 so that it is more rigid. For <code>gpt-5</code>, which is a reasoning model, the required temperature is 1, and Spring will throw an error if you try to set it to a different value.</p>



<p>Once the model is configured, we can build our service:</p>



<pre class="wp-block-code"><code>package com.infoworld.springaidemo.service;

import java.util.Map;

import com.infoworld.springaidemo.model.JokeResponse;
import com.infoworld.springaidemo.model.SimpleQueryResponse;

import org.springframework.ai.chat.client.ChatClient;
import org.springframework.ai.chat.prompt.Prompt;
import org.springframework.ai.chat.prompt.PromptTemplate;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.core.io.Resource;
import org.springframework.stereotype.Service;

@Service
public class SpringAIService {

    private final ChatClient chatClient;

    public SpringAIService(ChatClient.Builder chatClientBuilder) {
        this.chatClient = chatClientBuilder.build();
    }

    public String simpleQueryAsString(String query) {
        return this.chatClient.prompt(query).call().content();
    }

    public SimpleQueryResponse simpleQuery(String query) {
        return this.chatClient.prompt(query).call().entity(SimpleQueryResponse.class);
    }
}</code></pre>



<p>Because we have OpenAI configured in our <code>application.yaml</code> file, Spring will automatically create a <code>ChatClient.Builder</code> that we can wire into our service and then use it to create a <code>ChatClient</code>. The <code>ChatClient</code> is the main interface for interacting with chat-based models, such as GPT. In this example, we invoke its <code>prompt()</code> method, passing it our <code>String</code> query. The <code>prompt()</code> method also accepts a <code>Prompt</code> object, which you will see in a minute. The <code>prompt()</code> method returns a <code>ChatClientRequestSpec</code> instance that we can use to configure LLM calls. In this example, we simply invoke its <code>call()</code> method to send the message to the LLM. The <code>call()</code> method returns a <code>CallResponseSpec</code> instance. You can use that to get the text response by invoking its <code>content()</code> method, or you can map the response to an entity by invoking its <code>entity()</code> method. I provided examples of both. For the entity mapping, I passed a <code>SimpleQueryResponse</code>, which is a Java record:</p>



<pre class="wp-block-code"><code>package com.infoworld.springaidemo.model;

public record SimpleQueryResponse(String response) {
}</code></pre>



<p>Now let’s build a controller so that we can test this out:</p>



<pre class="wp-block-code"><code>package com.infoworld.springaidemo.web;

import com.infoworld.springaidemo.model.SimpleQuery;
import com.infoworld.springaidemo.model.SimpleQueryResponse;
import com.infoworld.springaidemo.service.SpringAIService;

import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class SpringAiController {
    private final SpringAIService springAIService;

    public SpringAiController(SpringAIService springAIService) {
        this.springAIService = springAIService;
    }

    @PostMapping("/simpleQuery")
    public ResponseEntity<SimpleQueryResponse> simpleQuery(@RequestBody SimpleQuery simpleQuery) {
        SimpleQueryResponse response = springAIService.simpleQuery(simpleQuery.query());
        return ResponseEntity.ok(response);
    }

}</code></pre>



<p>This controller wires in the <code>SpringAIService</code> and exposes a <code>PostMapping</code> to <code>/simpleQuery</code>. It accepts a <code>SimpleQuery</code> as its request body, which is another Java record:</p>



<pre class="wp-block-code"><code>package com.infoworld.springaidemo.model;

public record SimpleQuery(String query) {
}</code></pre>



<p>The <code>simpleQuery()</code> method passes the request body’s query parameter to the <code>SpringAIService</code> and then returns a response as a <code>SimpleQueryResponse</code>.</p>



<p>If you build the application, with <code>mvn clean install</code>, and then run it with <code>mvn spring-boot:run</code>, you can execute a <code>POST</code> request to <code>/simpleQuery</code> and get a response. For example, I posted the following <code>SimpleQuery</code>:</p>



<pre class="wp-block-code"><code>{
    "query": "Give me a one sentence summary of Spring AI"
}</code></pre>



<p>And received the following response:</p>



<pre class="wp-block-code"><code>{
    "response": "Spring AI is a Spring project that offers vendor-neutral, idiomatic abstractions and starters to integrate LLMs and related AI capabilities (chat, embeddings, tools, vector stores) into Java/Spring applications."
}</code></pre>



<p>Now that you know how to configure a Spring application to use Spring AI, send a message to an LLM, and get a response, we can begin to explore prompts more deeply.</p>



<p><strong>Download the Spring AI tutorial source code.</strong></p>



<h3 class="wp-block-heading" id="supporting-user-input-with-spring-ai-prompt-templates">Supporting user input with Spring AI prompt templates</h3>



<p>Sending a message to an LLM is a good first step in understanding Spring AI, but it is not very useful for solving business problems. Many times, you want to control the prompt and allow the user to specify specific parameters, and this is where prompt templates come in. Spring AI supports prompt templates through the <code>PromptTemplate</code> class. You can define prompt templates in-line, but the convention in Spring AI is to define your templates in the src/resources/templates directory using an st extension.</p>



<p>For our example, we’ll create a prompt template that asks the LLM to tell us a joke, but in this case, we’ll have the user provide the type of joke, such as silly or sarcastic, and the topic. Here is my <code>joke-template.st</code> file:</p>



<pre class="wp-block-code"><code>Tell me a {type} joke about {topic}</code></pre>



<p>We define the template as a <code>String</code> that accepts variables, which in this case are a type and a topic. We can then import this template into our class using a Spring property value. I added the following to the <code>SpringAIService</code>:</p>



<pre class="wp-block-code"><code>@Value("classpath:/templates/joke-template.st")
    private Resource jokeTemplate;</code></pre>



<p>The value references the classpath, which includes the files found in the <code>src/main/resources</code> folder, then specifies the path to the template.</p>



<p>Next, I added a new <code>tellMeAJoke() </code>method to the <code>SpringAIService</code>:</p>



<pre class="wp-block-code"><code>public JokeResponse tellMeAJoke(String type, String topic) {
        Prompt prompt = new PromptTemplate(jokeTemplate)
                .create(Map.of("type", type, "topic", topic));
        return this.chatClient.prompt(prompt).call().entity(JokeResponse.class);
    }</code></pre>



<p>This method accepts a type and a topic and then constructs a new <code>PromptTemplate</code> from the <code>joke-template.st</code> file that we wired in above. To set its values, we pass a map of the values in the <code>PromptTemplate</code>’s <code>create()</code> method, which returns a <code>Prompt</code> for us to use. Finally, we use the <code>ChatClient</code>, but this time we pass the prompt to the <code>prompt()</code> method instead of the raw string, then we map the response to a <code>JokeResponse</code>:</p>



<pre class="wp-block-code"><code>package com.infoworld.springaidemo.model;

public record JokeResponse(String response) {
}</code></pre>



<p>I updated the controller to create a new <code>/tellMeAJoke</code> <code>PostMapping</code>:</p>



<pre class="wp-block-code"><code>@PostMapping("/tellMeAJoke")
    public ResponseEntity<JokeResponse> tellMeAJoke(@RequestBody JokeRequest jokeRequest) {
        JokeResponse response = springAIService.tellMeAJoke(jokeRequest.type(), jokeRequest.topic());
        return ResponseEntity.ok(response);
    }</code></pre>



<p>The request body is a <code>JokeRequest</code>, which is another Java record:</p>



<pre class="wp-block-code"><code>package com.infoworld.springaidemo.model;

public record JokeRequest(String type, String topic) {
}</code></pre>



<p>Now we can <code>POST</code> a JSON body with a type and topic and it will tell us a joke. For example, I sent the following <code>JokeRequest</code> to ask for a silly joke about Java:</p>



<pre class="wp-block-code"><code>    "type": "silly",
    "topic": "Java"
}</code></pre>



<p>And OpenAI returned the following:</p>



<pre class="wp-block-code"><code>{
    "response": "Why do Java developers wear glasses? Because they don't C#."
}</code></pre>



<p>While this is a trivial example, you can use the code here as a scaffold to build robust prompts and accept simple input from users, prompting OpenAI or another LLM to generate meaningful results.</p>



<h3 class="wp-block-heading" id="retrieval-augmented-generation-with-spring-ai">Retrieval augmented generation with Spring AI</h3>



<p>The examples we’ve built so far are very much “toy” examples, but they illustrate how to configure an LLM and execute calls to it with Spring AI. Now let’s look at something more useful. Retrieval augmented generation, or RAG, is important in the AI space because it allows us to leverage LLMs to answer questions they were not trained on, such as internal company documents. The process is conceptually very simple, but the implementation details can be confusing if you don’t have a good foundation in what you are doing. This section will build that foundation so you can start using RAG in your Spring AI programs.</p>



<p>To start, let’s say we create a prompt with the following format:</p>



<pre class="wp-block-code"><code>Use the following context to answer the user's question.
If the question cannot be answered from the context, state that clearly.

Context:
{context}

Question:
{question}</code></pre>



<p>We provide the <em>context</em>, which is the information we want the LLM to use to answer the question, along with the question we want the LLM to answer. This is like giving the LLM a cheat sheet: The answer is here, and you just need to extract it to answer the question. The real challenge is how to store and retrieve the context we want the LLM to use. For example, you might have thousands of pages in a knowledge base that contains everything about your product, but you shouldn’t send all that information to the LLM. It would be very expensive to ask the LLM to process that much information. Besides, each LLM has a token limit, so you couldn’t send all of it even if you wanted to. Instead, we introduce the concept of a vector store.</p>



<p>A vector store is a database that contains documents. The interesting thing about these documents is that the vector store uses an embedding algorithm to create a multi-dimensional vector for each one. Then, you can create a similar vector for your question, and the vector store will compute a similarity score comparing your question to the documents in its database. Using this approach, you can take your question, retrieve the top three to five documents that are similar to your question, and use that as the context in the prompt.</p>



<p>Here’s a flow diagram summarizing the process of using a vector store:</p>


<div class="extendedBlock-wrapper block-coreImage undefined"><p class="imageCredit">Steven Haines</p></div>



<p>First, you gather all your documents, chunk them into smaller units, and add them to the vector store. There are different chunking strategies, but you can chunk the documents into a specific number of words, paragraphs, sentences, and so forth, including overlapping sections so that you don’t lose too much context. The smaller the chunk is, the more specific it is, but the less context it retains. Larger chunks retain more context, but lose a lot of specific knowledge, which makes similarity searches more difficult. Finding the right size for your data chunks is a balancing act and requires experimenting on your own dataset.</p>



<p>For our example, I took some text from the public Spring AI documentation and stored it in three text files included with the source code for this article. We’ll use this text with Spring AI’s SimpleVectorStore, which is an in-memory vector store that you can use for testing. Spring AI supports production-scale vector stores like Pinecone, Qdrant, Azure AI, PGvector, and more, but using SimpleVectorStore works for this example.</p>



<p>I added the following <code>SpringRagConfig</code> configuration class to the example code developed so far:</p>



<pre class="wp-block-code"><code>package com.infoworld.springaidemo;

import java.io.IOException;
import java.util.List;

import org.springframework.ai.document.Document;
import org.springframework.ai.embedding.EmbeddingModel;
import org.springframework.ai.reader.TextReader;
import org.springframework.ai.vectorstore.SimpleVectorStore;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.io.Resource;
import org.springframework.core.io.support.PathMatchingResourcePatternResolver;
import org.springframework.core.io.support.ResourcePatternResolver;

@Configuration
public class SpringRagConfig {

    @Bean
    public SimpleVectorStore simpleVectorStore(EmbeddingModel embeddingModel) throws RuntimeException {
        // Use the builder to create and configure the SimpleVectorStore
        SimpleVectorStore simpleVectorStore = SimpleVectorStore.builder(embeddingModel)
                .build();
        try {
            ResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();
            Resource[] resources = resolver.getResources("classpath*:documents/**/*.txt");
            for(Resource resource : resources) {
                TextReader textReader = new TextReader(resource);
                List<Document> documents = textReader.get();
                simpleVectorStore.add(documents);
            }
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
        return simpleVectorStore;
    }
}</code></pre>



<p>This configuration class defines a Spring bean named <code>simpleVectorStore</code> that accepts an <code>EmbeddingModel</code>, which will automatically be created by Spring when it creates your LLM. It creates a new <code>SimpleVectorStore</code> by invoking the <code>SimpleVectorStore</code>’s static <code>builder()</code> method, passing it the embedding model, and calling its <code>build()</code> method. Then, it scans the classpath for all <code>txt</code> files in the <code>src/resources/documents</code> directory, reads them using Spring’s <code>TextReader</code>, retrieves their content as <code>Document</code> instances by calling the text reader’s <code>get()</code> method, and finally adds them to the <code>SimpleVectorStore</code>.</p>



<p>In a production environment, you can configure the production vector store in your <code>application.yaml</code> file and Spring will create it automatically. For example, if you wanted to configure Pinecone, you would add the following to your <code>application.yaml</code>:</p>



<pre class="wp-block-code"><code>spring:
  ai:
    vectorstore:
      pinecone:
        apiKey: ${PINECONE_API_KEY}
        environment: ${PINECONE_ENV}
        index-name: ${PINECONE_INDEX}
        projectId: ${PINECONE_PROJECT_ID}</code></pre>



<p>The <code>SimpleVectorStore</code> takes a little more configuration, but still keeps our test code simple. To use it, I first created a <code>rag-template.st</code> file:</p>



<pre class="wp-block-code"><code>Use the following context to answer the user's question.
If the question cannot be answered from the context, state that clearly.

Context:
{context}

Question:
{question}</code></pre>



<p>Then I created a new <code>SpringAIRagService</code>:</p>



<pre class="wp-block-code"><code>package com.infoworld.springaidemo.service;

import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;

import org.springframework.ai.chat.client.ChatClient;
import org.springframework.ai.chat.prompt.Prompt;
import org.springframework.ai.chat.prompt.PromptTemplate;
import org.springframework.ai.document.Document;
import org.springframework.ai.vectorstore.VectorStore;
import org.springframework.ai.vectorstore.SearchRequest;
import org.springframework.stereotype.Service;

@Service
public class SpringAIRagService {
    @Value("classpath:/templates/rag-template.st")
    private Resource promptTemplate;
    private final ChatClient chatClient;
    private final VectorStore vectorStore;

    public SpringAIRagService(ChatClient.Builder chatClientBuilder, VectorStore vectorStore) {
        this.chatClient = chatClientBuilder.build();
        this.vectorStore = vectorStore;
    }

    public String query(String question) {
        SearchRequest searchRequest = SearchRequest.builder()
                .query(question)
                .topK(2)
                .build();
        List<Document> similarDocuments = vectorStore.similaritySearch(searchRequest);
        String context = similarDocuments.stream()
                .map(Document::getText)
                .collect(Collectors.joining("\n"));

        Prompt prompt = new PromptTemplate(promptTemplate)
                .create(Map.of("context", context, "question", question));

        return chatClient.prompt(prompt)
                .call()
                .content();
    }
}</code></pre>



<p>The <code>SpringAIRagService</code> wires in a <code>ChatClient.Builder</code>, which we use to build a <code>ChatClient</code>, along with our <code>VectorStore</code>. The <code>query()</code> method accepts a question and uses the <code>VectorStore</code> to build the context. First, we need to build a <code>SearchRequest</code>, which we do by:</p>



<ul class="wp-block-list">
<li>Invoking its static <code>builder()</code> method. </li>



<li>Passing the question as the query. </li>



<li>Using the <code>topK() method to specify how many documents we want to retrieve from the vector store.</code></li>



<li>Calling its <code>build()</code> method.</li>
</ul>



<p>In this case, we want to retrieve the top two documents that are most similar to the question. In practice, you’ll use something larger, such as the top three or top five, but since we only have three documents, I limited it to two.</p>



<p>Next, we invoke the vector store’s <code>similaritySearch()</code> method, passing it our <code>SearchRequest</code>. The <code>similaritySearch()</code> method will use the vector store’s embedding model to create a multidimensional vector of the question. It will then compare that vector to each document and return the documents that are most similar to the question. We stream over all similar documents, get their text, and build a context <code>String</code>.</p>



<p>Next, we create our prompt, which tells the LLM to answer the question using the context. Note that it is important to tell the LLM to use the context to answer the question and, if it cannot, to state that it cannot answer the question from the context. If we don’t provide these instructions, the LLM will use the data it was trained on to answer the question, which means it will use information not in the context we’ve provided.</p>



<p>Finally, we build the prompt, setting its context and question, and invoke the <code>ChatClient</code>. I added a <code>SpringAIRagController</code> to handle <code>POST</code> requests and pass them to the <code>SpringAIRagService</code>:</p>



<pre class="wp-block-code"><code>package com.infoworld.springaidemo.web;

import com.infoworld.springaidemo.model.SpringAIQuestionRequest;
import com.infoworld.springaidemo.model.SpringAIQuestionResponse;
import com.infoworld.springaidemo.service.SpringAIRagService;

import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class SpringAIRagController {
    private final SpringAIRagService springAIRagService;

    public SpringAIRagController(SpringAIRagService springAIRagService) {
        this.springAIRagService = springAIRagService;
    }

    @PostMapping("/springAIQuestion")
    public ResponseEntity<SpringAIQuestionResponse> askAIQuestion(@RequestBody SpringAIQuestionRequest questionRequest) {
        String answer = springAIRagService.query(questionRequest.question());
        return ResponseEntity.ok(new SpringAIQuestionResponse(answer));
    }
}</code></pre>



<p>The <code>askAIQuestion()</code> method accepts a <code>SpringAIQuestionRequest</code>, which is a Java record:</p>



<pre class="wp-block-code"><code>package com.infoworld.springaidemo.model;

public record SpringAIQuestionRequest(String question) {
}</code></pre>



<p>The <code>SpringAIQuestionRequest</code> returns a <code>SpringAIQuestionResponse</code>:</p>



<pre class="wp-block-code"><code>package com.infoworld.springaidemo.model;

public record SpringAIQuestionResponse(String answer) {
}</code></pre>



<p>Now restart your application and execute a <code>POST</code> to <code>/springAIQuestion</code>. In my case, I sent the following request body:</p>



<pre class="wp-block-code"><code>{
    "question": "Does Spring AI support RAG?"
}</code></pre>



<p>And received the following response:</p>



<pre class="wp-block-code"><code>{
    "answer": "Yes. Spring AI explicitly supports Retrieval Augmented Generation (RAG), including chat memory, integrations with major vector stores, a portable vector store API with metadata filtering, and a document injection ETL framework to build RAG pipelines."
}</code></pre>



<p>As you can see, the LLM used the context of the documents we loaded into the vector store to answer the question. We can further test whether it is following our directions by asking a question that is not in our context:</p>



<pre class="wp-block-code"><code>{
    "question": "Who created Java?"
}</code></pre>



<p>Here is the LLM’s response:</p>



<pre class="wp-block-code"><code>{
    "answer": "The provided context does not include information about who created Java."
}</code></pre>



<p>This is an important validation that the LLM is only using the provided context to answer the question and not using its training data or, worse, trying to make up an answer.</p>



<h3 class="wp-block-heading" id="conclusion">Conclusion</h3>



<p>This article introduced you to using Spring AI to incorporate large language model capabilities into Spring-based applications. You can configure LLMs and other AI technologies using Spring’s standard <code>application.yaml</code> file, then wire them into Spring components. Spring AI provides an abstraction to interact with LLMs, so you don’t need to use LLM-specific SDKs. For experienced Spring developers, this entire process is similar to how Spring Data abstracts database interactions using Spring Data interfaces.</p>



<p>In this example, you saw how to configure and use a large language model in a Spring MVC application. We configured OpenAI to answer simple questions, introduced prompt templates to externalize LLM prompts, and concluded by using a vector store to implement a simple RAG service in our example application.</p>



<p>Spring AI has a robust set of capabilities, and we’ve only scratched the surface of what you can do with it. I hope the examples in this article provide enough foundational knowledge to help you start building AI applications using Spring. Once you are comfortable with configuring and accessing large language models in your applications, you can dive into more advanced AI programming, such as building AI agents to improve your business processes.</p>



<p><strong>Read next: The hidden skills behind the AI engineer.</strong></p>
</div></div></div></div>
  </div>
  <p>
    Sources:
    <span itemprop="author" itemscope itemtype="https://schema.org/Person">
      <a itemprop="url" href="https://www.infoworld.com/article/4091447/spring-ai-tutorial-get-started-with-spring-ai.html" rel="external noreferrer nofollow noopener" target="_blank">
        <span itemprop="name">Info World</span>
      </a>
    </span><br>
    Published:
    <span itemprop="datePublished">Dec 4, 2025, 4:00:00 AM EST</span>
  </p>
</div>
</main>
<footer>
  <div class="links">
    <a href="/terms/">Terms of Service</a> •
    <a href="/privacy/">Privacy Policy</a> •
    <a href="/disclaimer/">Disclaimer</a>
  </div>
  <div class="copy">
    <span class="icons" itemscope itemtype="https://schema.org/Organization">
      <meta itemprop="name" content="Major Digest">
      <meta itemprop="description" content="Reliable and Comprehensive News Sources">
      <meta itemprop="naics" content="513110">
      <link itemprop="url" href="https://majordigest.com/">
      <link itemprop="logo" href="https://majordigest.com/assets/icons/logo-512x512.png">
      <a href="https://x.com/major_digest/" rel="external" target="_blank" itemprop="sameAs" title="Follow us on X (Twitter)" aria-label="Follow us on X (Twitter)"><svg role="img" aria-label="X Logo" xmlns="http://www.w3.org/2000/svg" version="1.1" x="0px" y="0px" width="24px" height="24px" viewBox="0 0 312 312"><path d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66"/></svg></a>
      <a href="https://www.facebook.com/majordigest" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Facebook" aria-label="Follow us on Facebook"><svg role="img" aria-label="Facebook Logo" xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" x="0px" y="0px" viewBox="0 0 455.73 455.73"><path d="M0,0v455.73h242.704V279.691h-59.33v-71.864h59.33v-60.353c0-43.893,35.582-79.475,79.475-79.475h62.025v64.622h-44.382 c-13.947,0-25.254,11.307-25.254,25.254v49.953h68.521l-9.47,71.864h-59.051V455.73H455.73V0H0z"/></svg></a>
      <a href="https://www.instagram.com/majordigest" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Instagram" aria-label="Follow us on Instagram"><svg role="img" aria-label="Instagram Logo" xmlns="http://www.w3.org/2000/svg" version="1.1" x="0px" y="0px" width="24px" height="24px" viewBox="0 0 169.063 169.063"><path d="M122.406,0H46.654C20.929,0,0,20.93,0,46.655v75.752c0,25.726,20.929,46.655,46.654,46.655h75.752 c25.727,0,46.656-20.93,46.656-46.655V46.655C169.063,20.93,148.133,0,122.406,0z M154.063,122.407 c0,17.455-14.201,31.655-31.656,31.655H46.654C29.2,154.063,15,139.862,15,122.407V46.655C15,29.201,29.2,15,46.654,15h75.752 c17.455,0,31.656,14.201,31.656,31.655V122.407z"></path><path d="M84.531,40.97c-24.021,0-43.563,19.542-43.563,43.563c0,24.02,19.542,43.561,43.563,43.561s43.563-19.541,43.563-43.561 C128.094,60.512,108.552,40.97,84.531,40.97z M84.531,113.093c-15.749,0-28.563-12.812-28.563-28.561 c0-15.75,12.813-28.563,28.563-28.563s28.563,12.813,28.563,28.563C113.094,100.281,100.28,113.093,84.531,113.093z"></path><path d="M129.921,28.251c-2.89,0-5.729,1.17-7.77,3.22c-2.051,2.04-3.23,4.88-3.23,7.78c0,2.891,1.18,5.73,3.23,7.78 c2.04,2.04,4.88,3.22,7.77,3.22c2.9,0,5.73-1.18,7.78-3.22c2.05-2.05,3.22-4.89,3.22-7.78c0-2.9-1.17-5.74-3.22-7.78 C135.661,29.421,132.821,28.251,129.921,28.251z"></path></svg></a>
      <a href="https://www.threads.net/majordigest" rel="external" target="_blank" itemprop="sameAs"  title="Follow us on Threads" aria-label="Follow us on Threads"><svg role="img" aria-label="Threads Logo" width="24px" height="24px" viewBox="0 0 192 192" xmlns="http://www.w3.org/2000/svg"><path d="M141.537 88.9883C140.71 88.5919 139.87 88.2104 139.019 87.8451C137.537 60.5382 122.616 44.905 97.5619 44.745C97.4484 44.7443 97.3355 44.7443 97.222 44.7443C82.2364 44.7443 69.7731 51.1409 62.102 62.7807L75.881 72.2328C81.6116 63.5383 90.6052 61.6848 97.2286 61.6848C97.3051 61.6848 97.3819 61.6848 97.4576 61.6855C105.707 61.7381 111.932 64.1366 115.961 68.814C118.893 72.2193 120.854 76.925 121.825 82.8638C114.511 81.6207 106.601 81.2385 98.145 81.7233C74.3247 83.0954 59.0111 96.9879 60.0396 116.292C60.5615 126.084 65.4397 134.508 73.775 140.011C80.8224 144.663 89.899 146.938 99.3323 146.423C111.79 145.74 121.563 140.987 128.381 132.296C133.559 125.696 136.834 117.143 138.28 106.366C144.217 109.949 148.617 114.664 151.047 120.332C155.179 129.967 155.42 145.8 142.501 158.708C131.182 170.016 117.576 174.908 97.0135 175.059C74.2042 174.89 56.9538 167.575 45.7381 153.317C35.2355 139.966 29.8077 120.682 29.6052 96C29.8077 71.3178 35.2355 52.0336 45.7381 38.6827C56.9538 24.4249 74.2039 17.11 97.0132 16.9405C119.988 17.1113 137.539 24.4614 149.184 38.788C154.894 45.8136 159.199 54.6488 162.037 64.9503L178.184 60.6422C174.744 47.9622 169.331 37.0357 161.965 27.974C147.036 9.60668 125.202 0.195148 97.0695 0H96.9569C68.8816 0.19447 47.2921 9.6418 32.7883 28.0793C19.8819 44.4864 13.2244 67.3157 13.0007 95.9325L13 96L13.0007 96.0675C13.2244 124.684 19.8819 147.514 32.7883 163.921C47.2921 182.358 68.8816 191.806 96.9569 192H97.0695C122.03 191.827 139.624 185.292 154.118 170.811C173.081 151.866 172.51 128.119 166.26 113.541C161.776 103.087 153.227 94.5962 141.537 88.9883ZM98.4405 129.507C88.0005 130.095 77.1544 125.409 76.6196 115.372C76.2232 107.93 81.9158 99.626 99.0812 98.6368C101.047 98.5234 102.976 98.468 104.871 98.468C111.106 98.468 116.939 99.0737 122.242 100.233C120.264 124.935 108.662 128.946 98.4405 129.507Z"></path></svg></a>
      <a href="https://t.me/majordigest" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Telegram" aria-label="Follow us on Telegram"><svg role="img" aria-label="Telegram Logo" width="24px" height="24px" viewBox="0 0 48 48" xmlns="http://www.w3.org/2000/svg"><path fill="none" stroke="black" stroke-linecap="round" stroke-linejoin="round" d="M40.83,8.48c1.14,0,2,1,1.54,2.86l-5.58,26.3c-.39,1.87-1.52,2.32-3.08,1.45L20.4,29.26a.4.4,0,0,1,0-.65L35.77,14.73c.7-.62-.15-.92-1.07-.36L15.41,26.54a.46.46,0,0,1-.4.05L6.82,24C5,23.47,5,22.22,7.23,21.33L40,8.69a2.16,2.16,0,0,1,.83-.21Z"/></svg></a>
<!--
      <a href="https://www.youtube.com/@MajorDigest" rel="external" target="_blank" itemprop="sameAs" title="Follow us on YouTube" aria-label="Follow us on YouTube"><svg role="img" aria-label="YouTube Logo" height="24px" width="24px" version="1.1" viewBox="0 0 461.001 461.00" xmlns="http://www.w3.org/2000/svg"><path d="M365.257,67.393H95.744C42.866,67.393,0,110.259,0,163.137v134.728 c0,52.878,42.866,95.744,95.744,95.744h269.513c52.878,0,95.744-42.866,95.744-95.744V163.137 C461.001,110.259,418.135,67.393,365.257,67.393z M300.506,237.056l-126.06,60.123c-3.359,1.602-7.239-0.847-7.239-4.568V168.607 c0-3.774,3.982-6.22,7.348-4.514l126.06,63.881C304.363,229.873,304.298,235.248,300.506,237.056z"/></svg></a>
      <a href="https://podcasts.apple.com/us/podcast/major-digest-podcast/id1769748189" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Apple Podcasts" aria-label="Follow us on Apple Podcasts"><svg role="img" aria-label="Apple Podcasts Logo" width="21px" height="21px" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg"><path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg></a>
      <a href="https://podcasters.spotify.com/pod/show/majordigest/" rel="external" target="_blank" itemprop="sameAs" title="Follow us on Spotify" aria-label="Follow us on Spotify"><svg role="img" aria-label="Spotify Logo" width="28px" height="28px" viewBox="0 -2 30 30" version="1.1" xmlns="http://www.w3.org/2000/svg"><path d="M13.2 20.84c-0.2 0-0.4-0.080-0.56-0.2-1.84-1.6-5.8-1.12-7.2-0.84-0.44 0.12-0.92-0.2-1-0.64-0.12-0.44 0.2-0.88 0.64-1 0.24-0.040 5.8-1.24 8.64 1.2 0.36 0.32 0.4 0.84 0.080 1.2-0.12 0.16-0.36 0.28-0.6 0.28zM14.2 18.44c-0.16 0-0.32-0.040-0.48-0.16-3.36-2.4-8.48-1.080-8.52-1.080-0.44 0.12-0.92-0.16-1.040-0.6s0.16-0.92 0.6-1.040c0.24-0.080 5.92-1.56 9.96 1.32 0.36 0.28 0.48 0.8 0.2 1.16-0.2 0.28-0.44 0.4-0.72 0.4zM15.24 15.72c-0.16 0-0.32-0.040-0.48-0.16-4.44-2.96-10.040-1.040-10.12-1.040-0.44 0.16-0.88-0.080-1.040-0.52s0.080-0.92 0.52-1.080c0.28-0.080 6.48-2.2 11.6 1.24 0.4 0.24 0.48 0.76 0.24 1.16-0.2 0.24-0.48 0.4-0.72 0.4zM9.6 25.6c-5.28 0-9.6-4.32-9.6-9.6s4.32-9.6 9.6-9.6 9.6 4.32 9.6 9.6-4.32 9.6-9.6 9.6zM9.6 8.080c-4.36 0-7.92 3.56-7.92 7.92s3.56 7.92 7.92 7.92 7.92-3.56 7.92-7.92-3.56-7.92-7.92-7.92z"></path></svg></a>
      <a href="https://play.google.com/store/apps/details?id=com.majordigest.android" rel="external" target="_blank" itemprop="sameAs" title="Download Android App" aria-label="Download Android App"><svg role="img" aria-label="Google Play Logo" xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" x="0px" y="0px" viewBox="0 0 32 32"><path d="M20.331 14.644l-13.794-13.831 17.55 10.075zM2.938 0c-0.813 0.425-1.356 1.2-1.356 2.206v27.581c0 1.006 0.544 1.781 1.356 2.206l16.038-16zM29.512 14.1l-3.681-2.131-4.106 4.031 4.106 4.031 3.756-2.131c1.125-0.893 1.125-2.906-0.075-3.8zM6.538 31.188l17.55-10.075-3.756-3.756z"/></svg></a>
-->
    </span>
    © 2025&nbsp;<a href="/about/" title="About Major Digest: A Journey from Idea to Publication">Major Digest</a>
    <small> (v.1.1.6)</small>
  </div>
</footer>

<meta itemprop="operatingSystem" content="All">
<meta itemprop="applicationCategory" content="LifestyleApplication">
<meta itemprop="softwareVersion" content="1.1.6">
<div itemprop="offers" itemscope itemtype="https://schema.org/Offer">
  <meta itemprop="price" content="0">
  <meta itemprop="priceCurrency" content="USD">
</div>
<!--
<div itemprop="aggregateRating" itemscope itemtype="https://schema.org/AggregateRating">
  <meta itemprop="ratingValue" content="5">
  <meta itemprop="ratingCount" content="2">
  <link itemprop="sameAs" href="https://play.google.com/store/apps/details?id=com.majordigest.android">
</div>
<div itemprop="potentialAction" itemscope itemtype="https://schema.org/ViewAction">
  <meta itemprop="name" content="Open Major Digest">
  <link itemprop="target" href="https://majordigest.com/">
  <link itemprop="target" href="android-app://com.majordigest.android/http/majordigest.com">
</div>
<link rel="alternate" href="android-app://com.majordigest.android/http/majordigest.com">
-->

<section id="consent-banner" aria-label="Consent Banner" role="dialog">
  By continuing to use this app, you agree to our 
  <a href="/terms/">Terms of Service</a> and <a href="/privacy/">Privacy Policy</a>. 
  You can learn more about how we use cookies by reviewing our 
  <a href="/privacy/">Privacy Policy</a>. 
  <button onclick="this.parentNode.style.display='none'">Close</button>
</section>
<section id="ios-pwa-prompt" aria-label="iOS Installation Prompt" role="dialog">
  To install this app on your device tap
  <svg xmlns="http://www.w3.org/2000/svg" width="16px" viewBox="0 0 20.88 27.25">
    <polyline points="13.13 8 20.38 8 20.38 26.75 0.5 26.75 0.5 8 7.5 8"/>
    <line x1="10.44" y1="17" x2="10.44"/>
    <line x1="10.48" y1="0.38" x2="15.28" y2="5.18"/>
    <line x1="10.44" y1="0.38" x2="5.64" y2="5.18"/>
  </svg>
  and then Add to Home Screen.
  <button onclick="this.parentNode.style.display='none'">Close</button>
</section>
<script src="/assets/script.js?v=1.1.6" async></script>

<script type="application/ld+json">
{
   "@context": "https://schema.org/",
   "@type": "PodcastSeries",
   "image": "https://majordigest.com/assets/icons/logo-512x512.png",
   "url": "https://podcasters.spotify.com/pod/show/majordigest/",
   "name": "Major Digest Podcast - Spotify Podcasts",
   "description": "Your daily dose of tech news, straight to your feed. From AI and software development to emerging innovations, we’ve got you covered. Join our community of tech enthusiasts and industry professionals for daily updates on the future of technology.",
   "webFeed": "https://anchor.fm/s/fb28fbbc/podcast/rss",
   "author": {
     "@type": "Person",
     "name": "Major Digest"
   }
}
</script>
<script type="application/ld+json">
{
   "@context": "https://schema.org/",
   "@type": "PodcastSeries",
   "image": "https://majordigest.com/assets/icons/logo-512x512.png",
   "url": "https://podcasts.apple.com/us/podcast/major-digest-podcast/id1769748189",
   "name": "Major Digest Podcast - Apple Podcasts",
   "description": "Your daily dose of tech news, straight to your feed. From AI and software development to emerging innovations, we’ve got you covered. Join our community of tech enthusiasts and industry professionals for daily updates on the future of technology.",
   "webFeed": "https://anchor.fm/s/fb28fbbc/podcast/rss",
   "author": {
     "@type": "Person",
     "name": "Major Digest"
   }
}
</script>

</body>
</html>
